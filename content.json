{"meta":{"title":"Wonny's note","subtitle":null,"description":null,"author":"Wonny","url":"https://jumpegg.github.io"},"pages":[],"posts":[{"title":"SQLAlchemy with Mysql","slug":"python-01","date":"2018-01-08T03:31:21.000Z","updated":"2018-01-08T04:37:13.291Z","comments":true,"path":"2018/01/08/python-01/","link":"","permalink":"https://jumpegg.github.io/2018/01/08/python-01/","excerpt":"","text":"SQLAlchemy 선택 배경Django 스터디를 하면서 프로젝트 들어가기 이전에 여러가지 관련 라이브러리를 찾다가 다른 스터디분의 “Mybatis 처럼 mapper 형식으로 DB를 사용할 수 있는 라이브러리가 있는가?” 라는 질문을 받고 이것저것 찾다보니 SQLAlchemy 를 찾게 되었다. SQLAlchemy 는 주로 Flask와 연동해서 사용하는 경우가 많았는데 Flask 연동중에 예상치 못한 문제가 생겻고 아직까지 해결 못해서 Django와 연동해서 사용해볼까 한다.공식 홈페이지 : http://www.sqlalchemy.org/ 설치12pip install sqlalchemy // sqlalchemy 설치pip install mysqlclient // mysql 에 접속을 위해 필요하다. 버전확인python 스크립트를 이용해서 설치가 되었는지 확인 가능하다 12import sqlalchemyprint sqlalchemy.__version__ 코드123456789101112131415161718192021222324252627282930from sqlalchemy import create_enginefrom sqlalchemy import Column, Integer, Unicode, Stringfrom sqlalchemy.ext.declarative import declarative_basename = \"YourDBUserName\"password = \"YourDBPassword\"host = \"YourDBAddress\"db = \"ChooseDatabase\"re_str = 'mysql://' + name + ':' + \\ password + '@' + host + '/' + db + ''# DB 접속을 위해 Enging 객체를 생성해야 하는데 # sqlalchemy.create_engine 에 DB접속 정보를 넘겨주면 생성할 수 있다.engine = create_engine(re_str, echo=True)# 매핑 선언을 위해 declarative_base를 사용한다.# ORM이 관리할 데이터 테이블을 매핑 시키기 위해 # 해당 테이블의 정보가 들어있는 클래스 declarative_base 를 상속해서 만든다.Base = declarative_base()class Store(Base): __tablename__ = 'stores' id = Column(Integer, primary_key=True) name = Column(Unicode(50), nullable=False) phone = Column(String(20))# create_all 메소드를 호출하면 Base가 알고 있는 모든 테이블이 생성된다.Base.metadata.create_all(engine) 출처pywebcookbookSQLAlchemy-DB-Connection 설정방법","categories":[{"name":"SQLAlchemy","slug":"SQLAlchemy","permalink":"https://jumpegg.github.io/categories/SQLAlchemy/"}],"tags":[{"name":"python","slug":"python","permalink":"https://jumpegg.github.io/tags/python/"}]},{"title":"isotope 설정문제","slug":"angular2-problem-02","date":"2017-12-31T02:21:03.000Z","updated":"2017-12-31T02:31:14.868Z","comments":true,"path":"2017/12/31/angular2-problem-02/","link":"","permalink":"https://jumpegg.github.io/2017/12/31/angular2-problem-02/","excerpt":"","text":"문제angular 프로젝트에 isotope를 적용시키는데 masonry를 import 시키는 부분에서 문제가 생김 원인isotope 플러그인에 masonry 관련 경로 설정이 잘못되어 있었음 해결올바른 해결방안인지는 확실하지 않다. node_modules/isotope-layout/js/layout-modes/masorny.js 파일에 define 에서 ‘masorny/masonry’ -&gt; ‘masorny-layout/masonry’ 로 변경해준다.","categories":[{"name":"문제해결","slug":"문제해결","permalink":"https://jumpegg.github.io/categories/문제해결/"}],"tags":[{"name":"isotope","slug":"isotope","permalink":"https://jumpegg.github.io/tags/isotope/"}]},{"title":"미해결 - WEB 녹음기","slug":"non-solve-01","date":"2017-08-09T12:26:50.000Z","updated":"2017-08-09T12:44:18.773Z","comments":true,"path":"2017/08/09/non-solve-01/","link":"","permalink":"https://jumpegg.github.io/2017/08/09/non-solve-01/","excerpt":"","text":"문제프로젝트 진행 중, 웹 상에서 녹음 기능을 구현해야 하는 상황이 생겼다. 크롬은 navigator.getUserMedia() 를 사용하여 쉽게 구현 가능했지만 IE에서는 지원하지 않는 API였기 때문에 구현에 어려움이 있었다. 시도 temasys adaptor 이 플러그인을 사용하면 WebRTC가 지원되지 않는 익스플로러에 ActiveX를 설치하는 것 처럼 기능을 설치해준다. 이후에 getUserMedia를 사용하여 stream을 얻을 수 있다. 12345678910111213let obj = this;AdaptorJS.webRTCReady(isUsingPlugin =&gt; &#123; getUserMedia(&#123; // getUserMedia 를 사용하게 해준다 audio: true, video: false &#125;, stream =&gt; &#123; // stream을 이용해 작업이 가능하다 // something login &#125;, error =&gt; &#123; console.log(error); &#125;)&#125;) stream을 통한 기능 구현 중…. 필자는 크롬에서 기능 구현을 위해 RecordRTC를 사용했다. 문제는 IE에서 RecordRTC가 정상 작동하지 않는다는 것. 직접 stream을 제어하기에는 필자의 실력이 부족했다. 구글링 결과 대부분 AudioContext를 통해 stream을 제어하는것을 봣지만 AudioContext도 IE에서는 미지원. 정리 IE에서 녹음기능 구현시도 temasys adaptor 를 사용해 IE에서도 getUserMedia 사용 가능 stream 제어를 위해 RecordRTC를 사용했지만 IE에서 지원하지 않음 AudioContext IE 미지원","categories":[{"name":"미해결","slug":"미해결","permalink":"https://jumpegg.github.io/categories/미해결/"}],"tags":[{"name":"WebAPI","slug":"WebAPI","permalink":"https://jumpegg.github.io/tags/WebAPI/"}]},{"title":"angular2 ngFor 문제해결","slug":"problem03","date":"2017-08-05T06:17:37.000Z","updated":"2017-08-05T06:43:20.801Z","comments":true,"path":"2017/08/05/problem03/","link":"","permalink":"https://jumpegg.github.io/2017/08/05/problem03/","excerpt":"","text":"문제 인식Daum api 를 사용하여 주소검색 엔진을 사용했었고, 검색된 결과를 list로 뿌려주는 작업을 했었다. 검색된 결과를 list로 보여주는 작업에 ngFor를 사용했는데, 검색된 결과가 바로 보여지지 않고 다른 작업을 하면 뒤늦게 반영되는 현상을 볼 수 있었다. 원인ngFor에 연동되는 Array 가 변동되었는데 angular가 인식하지 못했다. 해결Daum api의 키워드 검색을 사용하면 검색된 결과를 callback 안에서 사용하는데 angular에서 변화를 인식하지 못했기 때문에 바로 ngFor에 반영이 되지 않음 123456789101112searchAddress(keyword) &#123; this.placeResults = []; let obj = this; if(keyword != \"\") &#123; this.placesService.keywordSearch(keyword, function(status, result) &#123; if (status === daum.maps.services.Status.OK) &#123; // 데이터를 placeResults에 넣었지만 화면에는 반영이 안되었다. obj.placeResults = result.places; &#125; &#125;); &#125; &#125; 이러한 변화감지를 강제적으로 걸어주기 위해 angular에서는 NgZone을 제공하고 있다. NgZone은 @angular/core 에 있다. 12// NgZone을 import 하자import &#123;Component, ..... , NgZone&#125; from '@angular/core'; 12345678910111213141516171819202122232425262728293031// NgZone을 import 하자import &#123;Component, ..... , NgZone&#125; from '@angular/core';@Component(&#123; selector: 'YourSelector', template: 'YourTemplete'&#125;)export class YourComponent &#123; constructor(public zone:NgZone, //NgZone을 선언해주자 ...................) &#123; &#125; // do something .............. searchAddress(keyword) &#123; this.placeResults = []; let obj = this; if(keyword != \"\") &#123; this.placesService.keywordSearch(keyword, function(status, result) &#123; if (status === daum.maps.services.Status.OK) &#123; // 요렇게 NgZone을 쓰면된다 obj.zone.run(()=&gt;&#123; obj.placeResults = result.places; &#125;) &#125; &#125;); &#125; &#125;&#125; 정리angular에서는 몇몇 상황에서 detection이 벗어나는 상황에 사용하기 위해 NgZone을 제공하고 있으며, 감지범위를 벗어나는 경우에 사용할 수 있다.","categories":[{"name":"문제해결","slug":"문제해결","permalink":"https://jumpegg.github.io/categories/문제해결/"}],"tags":[{"name":"angular-model-detection","slug":"angular-model-detection","permalink":"https://jumpegg.github.io/tags/angular-model-detection/"}]},{"title":"CH 6 실행계획(6.1, 6.2)","slug":"mysql-explain1","date":"2017-08-05T05:17:20.000Z","updated":"2017-08-09T12:56:27.716Z","comments":true,"path":"2017/08/05/mysql-explain1/","link":"","permalink":"https://jumpegg.github.io/2017/08/05/mysql-explain1/","excerpt":"","text":"6.1 개요6.1.1 쿼리 실행 절차Mysql 서버에서 쿼리가 실행되는 과정은 크게 3가지로 나눌 수 있다. 사용자로부터 요청된 sql 문장을 잘게 쪼개서 Mysql 서버가 이해할 수 있는 수준으로 분리한다. sql의 파싱 정보를 확인하면서 어떤 테이블부터 읽고 어떤 인덱스를 이용해 테이블을 읽을지 선택한다. 두 번째 단계에서 결정된 테이블의 읽기 순서나 선택된 인덱스를 이용해 스토리지 엔진으로 부터 데이터를 가져온다. 첫번째 단계를 sql 파싱 이라고 하며, Mysql 서버의 sql 파서 라는 모듈로 처리한다. 만약 문법이 잘못되었다면 이 단계에서 걸러진다. 또한 이 단계에서 sql 파스 트리 가 만들어진다. 두번째 단계는 sql 파스 트리 를 참조하면서 다음과 같은 내용을 처리한다. 불필요한 조건의 제거 및 복잡한 연산의 단순화 여러 테이블의 조인이 있는 경우 어떤 순서로 테이블을 읽을지 결정 각 테이블에 사용된 조건과 인덱스 통계 정보를 이용해 사용할 인덱스 결정 가져온 레코드들을 임시 테이블에 넣고 다시 한번 가공해야 하는지 결정 두번째 단계에서는 최적화 및 실행 계획 수립 단계이며 Mysql 서버의 옵티마이저 에서 처리한다. 6.1.2 옵티마이저의 종류옵티마이저는 데이터베이스 서버에서 두뇌와 같은 역할을 담당하고 있다. 옵티마이저는 비용 기반 최적화(Cost-based optimizer, CBO)방법과 규칙 기반 최적화 방법(Rule-based optimizer, RBO)으로 크게 나눠 볼 수 있다. 규칙 기반 최적화는 옵티마이저에 내장된 우선순위에 따라 실행 계획을 수립하는 방식을 의미한다. 현재 들어와 있는 데이터들의 통계정보를 사용하지 않기 때문에 상황에 따른 효율성이 다르다. 비용 기반 최적화는 쿼리를 처리하기 위한 여러가지 방법을 만들고, 각 단위 작업의 비용 정보와 대상 테이블의 예측된 통계정보를 이용해 각 실행 계획별 비용을 산출한다. 이렇게 산출된 각 실행 방법별로 최소 비용이 소요되는 처리 방식을 선택해 최종 쿼리를 실행한다. 6.1.3 통계 정보현재 대부분의 RDBMS는 비용 기반의 옵티마이저를 선택하고 있다. 비용 기반 최적화에서 가장 중요한 것은 통계정보다. 통계 정보가 정확하지 않다면 전혀 엉뚱한 방향으로 쿼리를 실행해 버릴 수 있기 때문이다. Mysql에서 관리되는 통계 정보는 대략의 레코드 건수와 인덱스의 유니크한 값의 개수 정보가 전부다. Mysql통계 정보는 순간순간 자동으로 변경되지만 ANALYZE를 통해 강제적으로 갱신할 수 있다.","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"explain","slug":"explain","permalink":"https://jumpegg.github.io/tags/explain/"}]},{"title":"CH 2 다양한 Nosql 데이터베이스(2.1, 2.2)","slug":"nosql02","date":"2017-07-25T06:24:27.000Z","updated":"2017-07-25T06:42:05.683Z","comments":true,"path":"2017/07/25/nosql02/","link":"","permalink":"https://jumpegg.github.io/2017/07/25/nosql02/","excerpt":"","text":"2.3 Nosql 데이터베이스의 네 가지 유형Nosql 데이터베이스의 유형은 다음과 같다. 키-값 데이터베이스 문서 데이터베이스 컬럼 패밀리 데이터베이스 그래프 데이터베이스 키-값 데이터베이스키-값 데이터베이스는 가장 간단한 형태의 Nosql 데이터베이스로 키와 값이라는 두 가지 요소가 있다. 키는 고유값이다. 값은 키와 함께 저장되는 데이터를 말한다. 키-값 데이터베이스는 값을 저장할 때 꽤 많은 유연성을 부여한다. 데이터의 타입을 엄격히 제한하지 않기 때문이다. 하지만 이러한 특성 때문에 개발자들은 프로그램에서 데이터 확인 로직을 구현해야한다. 키-값 데이터베이스는 데이터의 저장과 조회라는 최소한의 원칙에 따라서 만들어졌다. 관계형 데이터베이스와는 달리 키-값 데이터베이스에는 테이블이 없고 컬럼과 제약 조건처럼 테이블과 연관된 특성도 없다. 조인이 필요 없으므로 외부 키도 없고, SQL같은 질의 언어도 지원하지 않는다. 일부 키-값 데이터베이스는 데이터베이스 하나에서 독립된 이름공간을 여러 개 생성하기 위해 버킷이나 컬렉션을 지원한다. 이들은 관계형 스키마와 유사한 것들을 구현하는 데 사용될 수 있는데, 특히 키-이름 규칙과 결합할 때 더욱 그렇다. 문서 데이터베이스","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://jumpegg.github.io/categories/Nosql/"}],"tags":[]},{"title":"CH 2 다양한 Nosql 데이터베이스(2.1, 2.2)","slug":"nosql01","date":"2017-07-25T04:27:13.000Z","updated":"2017-07-25T06:25:18.121Z","comments":true,"path":"2017/07/25/nosql01/","link":"","permalink":"https://jumpegg.github.io/2017/07/25/nosql01/","excerpt":"","text":"2.1 분산 데이터베이스에서의 데이터 관리일반적인 데이터베이스에서 데이터를 저장하고 조회하는 목적을 달성하기 위해 데이터베이스 관리 시스템은 다음 세 가지 기능을 수행해야 한다. 영구적인 데이터 저장 데이터 일관성 유지 데이터 가용성 확보 영구적인 데이터 저장데이터는 영구적으로 저장되어야 한다. 이 말은 데이터베이스 서버가 고장나더라도 데이터는 소실되지 않고 저장되어야 한다는 뜻이다. 따라서 데이터는 디스크, 플래시, 테이프, 혹은 다른 장기기억장치에 저장된 데이터만이 영구적으로 저장됐다고 볼 수 있다. 데이터 일관성 유지흔히 둘 이상의 사람이 데이터베이스를 사용하면서 같은 데이터를 동시에 사용하고자 할 때 읽기와 쓰기에 관한 이슈가 발생한다. 이 때 한 사람이 여러 데이터를 변경하면, 모든 데이터가 변경이 완료되었을때 다른 사람이 변경내역을 조회할 수 있도록 하는것이 데이터 일관성이라고 한다. 이렇게 여러 단계에 걸쳐 일어나는 과정을 단일작업처럼 처리하는 것을 트랜잭션이라 한다. 데이터 가용성 확보데이터베이스는 수많은 원인으로 사용 불가 상태가 될 수 있다. 이러한 상황을 피하는 한 가지 방법은 두 대의 데이터베이스 서버를 운용하는 것이다. 데이터를 갱신하고 요청된 질의에 응답하는 데 사용되는 서버를 주 서버, 다른 서버를 백업 서버라고 한다. 백업 서버는 주 서버에 있는 데이터베이스의 복사본이다. 데이터베이스 트랜잭션 작업으로 주 서버에 데이터를 넣고 백업서버에 복사하는 과정까지 하나의 과정으로 묶으면 데이터의 일관성이 유지된다. 이렇게 데이터베이스 서버 두 대를 운용하면 서버 하나가 고장 나더라도 다른 한 대의 서버를 사용할 수 있다는 장점이 있다. 쓸만하지만 비용 문제가 수반되는 방식이며, 데이터베이스 애플리케이션과 애플리케이션 사용자는 데이터 쓰기 작업이 완료될 때까지 기다려야 한다는 단점이 있다. 응답 시간 - 일관성 - 지속성 간의 균형 맞추기Nosql 데이터베이스는 결과적 일관성을 구현한다. 즉, 데이터 복사본들이 다른 값을 갖는 시기가 있지만 결국에는 모든 복사본이 같은 값을 갖게 된다는 뜻이다. Nosql 데이터베이스는 종종 읽기와 쓰기 작업을 할 때 쿼럼이란 개념을 사용한다. 쿼럼은 완료되었다고 여겨지는 읽기나 쓰기 작업에 반드시 응답해야 하는 서버의 수를 말한다. 읽기 작업이 수행될 때 Nosql 데이터베이스는 서버 여러 대에서 데이터를 읽는다. 읽기 작업에 올바른 응답을 하는 한 가지 방법은 해당 데이터가 저장된 모든 서버에 질의하는 것이다. 그리고 데이터베이스는 반환되는 응답값 중 유일한 응답값의 수를 세어 구성임계값(configurable threshold)과 같거나 이를 초과하는 응답값을 반환한다. 읽기 임계값을 작게 할 수록 응답은 빨라지지만 일관성이 깨진 데이터가 반환될 위험은 커진다. 예를 들면 서버 5대에 데이터를 복제하는경우, 읽기 임계값을 3으로 잡으면 3대에 복제가 된 상태에서 데이터를 반환하게 된다. CAP 이론: 일관성, 가용성, 그리고 파티셔닝컴퓨터 과학자인 에릭 브루어의 이론으로 알려진 CAP 이론은, 분산 데이터베이스는 일관성(C), 가용성(A), 파티션 허용(P) 이 세가지 속성을 동시에 가질 수 없다는 내용이다. 여기서 일관성은 서버 간에 일관된 데이터를 유지함, 가용성은 질의에 대한 응답을 제공함, 파티션 허용은 둘 이상의 데이터베이스 서버가 연결된 네트워크에 문제가 생기더라도 이 서버들은 여전히 일관된 데이터를 갖고 있다는 뜻이다. 2.2 ACID 와 BASEACID: 원자성, 일관성, 고립성, 지속성A는 원자성 Atomicity 을 가리킨다. 원자성이란 말 그대로 더는 분할되지 않는 단위를 말한다. 트랜잭션처럼여러 단계를 한번에 처리하는것은 하나의 처리단위로 봐야 한다는 것이다. C는 일관성 Consistency 을 의미한다. 관계형 데이터베이스에서는 엄격한 일관성 이라고도 한다. 다른 말로 풀어 설명하면 트랜잭션은 데이터의 무결성을 위반한 상태로 데이터베이스를 내버려 두지 않는다는 뜻이다. I는 고립성 Isolation 을 뜻한다. 고립된 트랜잭션은 완료되기 전까지 다른 사용자들에게 보이지 않는다. D는 지속성 Durability 을 뜻한다. 일단 한 트랜잭션이나 작업 하나가 완료되면 서버에 전원공급이 끊어지는 상황에서도 데이터가 완료된 상태로 남아 있음을 의미한다. 즉 데이터가 디스크나 플래시 등의 영구저장매채에 저장된다는 뜻이다. 관계형 데이터베이스 관리 시스템은 ACID 트랜잭션을 지원하도록 설계되었다. Nosql 데이터베이스는 일반적으로 BASE 트랜잭션을 지원하는데, 일부 Nosql 데이터베이스는 일정 수준에서 ACID 트랜잭션을 지원하기도 한다. BASE: 기본적인 가용성, 소프트 상태, 결과적 일관성BA는 기본적인 가용성 Basically Available 을 뜻한다. 이 말은 분산 시스템에서 부분적인 고장이나 실패는 있을 수 있지만, 시스템의 나머지 부분은 계속 기능을 수행한다는 의미다. Nosql 데이터베이스는 종종 다른 서버에 복사본을 여러 개 만들어 두어, 서버 중 한 대에 문제가 생기더라도 요청된 질의에 응답할 수 있게 한다. S는 소프트 상태 Soft State 를 가리킨다. 일반적으로 컴퓨터 과학에서 소프트 상태는 새로 고쳐지지 않으면 데이터가 소실된다는 뜻이다. Nosql에서 소프트 상태란 결국 데이터가 더 최신 상태인 데이터로 덮여 쓰이는 것을 마한다. E는 결과적 일관성 Eventually Consistent 을 말한다. 이 말은 데이터베이스가 일관성이 없는 상태가 될때가 있음을 의미한다. 결과적 일관성의 유형결과적 일관성은 Nosql 데이터베이스에서 매우 중요한 특성이다. 결과적 일관성에는 다음과 같이 몇 가지 유형이 있다. 인과적 일관성 casual consistency 최신 데이터 읽기 일관성 read-your-writes consistency 세션 일관성 session consistency 단조 읽기 일관성 monotonic read consistency 단조 쓰기 일관성 monotonic write consistency 인과적 일관성인과적 일관성은 데이터베이스가 작업이 갱신된 순서를 반영하는 것을 보장한다. 예를들어 A가 데이터를 1000으로 변경하고, 1초뒤 B가 데이터를 2000 변경하면, 이 데이터의 모든 복사본은 먼저 1000으로 갱신된 후 2000으로 갱신된다. 최신 데이터 읽기 일관성최신 데이터 읽기 일관성은 일단 레코드 하나를 갱신했다면 이 레코드에 대한 모든 질의는 갱신된 값을 반환받는다는 의미로 이전에 기록한 값과 일치하지 않는 값을 반환받을 일은 절대 없다는 것이다. 세션 일관성세션 일관성은 세션이 살아있는 동안 최신 데이터 읽기 일관성을 보장한다. 세션이란 클라이언트와 서버 간, 혹은 사용자와 데이터베이스 간의 대화라고 생각하면 된다. 이러한 대화가 지속되는 한 데이터베이스는 대화 중 수행했던 모든 읽기 작업을 기억하고 있다. 만약 세션이 종료되고 같은 서버와 또 다른 세션을 연결했다면 이 서버가 이전 세션에서 수행한 내역을 기억할거라고 보장할 수 없다. 단조 읽기 일관성단조 읽기 일관성은 질의를 해서 그 결과를 볼 때 해당 값의 이전버전은 절대 볼 수 없다는 뜻이다. 단조 쓰기 일관성단조 쓰기 일관성은 몇 개의 갱신 명령어를 실행했을 때 이 명령어들이 실행된 순서대로 처리됨을 뜻한다.","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://jumpegg.github.io/categories/Nosql/"}],"tags":[]},{"title":"CH 5 인덱스(5.7)","slug":"mysql-index4","date":"2017-07-23T05:11:54.000Z","updated":"2017-07-29T14:52:48.400Z","comments":true,"path":"2017/07/23/mysql-index4/","link":"","permalink":"https://jumpegg.github.io/2017/07/23/mysql-index4/","excerpt":"","text":"5.7 전문 검색(Full Text search) 인덱스문서의 내용 전체를 인덱스화해서 특정 키워드가 포함된 문서를 검색하는 전문(Full Text) 검색에는 일반적인 스토리지 엔진에서 제공하는 B-Tree 인덱스를 사용할 수 없다. 문서 전체에 대한 분석과 검색을 위한 이러한 인덱싱 알고리즘을 전문 검색(Full Text search) 인덱스 라고 하는데, 전문 검색 인덱스는 일반화된 기능의 명칭이지 전문 검색 알고리즘의 이름을 지칭하는 것은 아니다. 전문 검색 인덱스에는 문서의 키워드를 인덱싱하는 기법에 따라 크게 구분자(Stopword)와 N-그램으로 나눠서 생각해 볼 수 있다. 5.7.1 인덱스 알고리즘구분자 기법전문의 내용을 공백이나 탭 또는 마침표와 같은 문장 기호, 그리고 사용자가 정의한 문자열을 구분자로 등록한다. 구분자 기법은 이처럼 등록된 구분자를 이용해 키워드를 분석해 내고, 결과 단어를 인덱스로 생성해 두고 검색에 이용하는 방법을 말한다. 구분자 기법은 문서의 본문으로 부터 키워드를 추출해 내는 작업이 추가로 필요할 뿐, 내부적으로는 B-Tree 인덱스를 그대로 사용한다. 전문 검색 인덱스의 많은 부분은 B-Tree의 특성을 따르지만 전문 검색 엔진을 통해 조회되는 레코드는 검색어나 본문 내용으로 정렬되어 조회되지는 않는다. 전문 검색에서 결과의 정렬은 일치율(Match percent)이 높은 순으로 출력되는 것이 일반적이다. N-그램(n-Gram) 기법구분자 기법은 B-Tree의 특성을 따르기 때문에 그 단점도 따르게 된다. 또한 각 국가의 언어 문법이 다양한데 하나의 규칙을 적용해 키워드를 추출하기는 쉽지 않다. 이러한 단점을 보완한것이 N-그램 방식이다. N-그램이란 본문을 무조건적으로 몇 글자씩 잘라서 인덱싱하는 방법이다. 구분자에 의한 방법보다는 인덱싱 알고리즘이 복잡하고, 만들어진 인덱스의 크기도 상당히 큰 편이다. N-그램에서 n은 인덱싱할 키워드의 최소 글자(또는 바이트)수를 의미하는데, 일반적으로 2글자 단위로 키워드를 쪼개서 인덱싱 하는 2-Gram(또는 Bi-Gram 이라고도 한다)방식이 많이 사용된다. 여기서도 2글자 키워드 방식의 2-Gram 위주로 알아보겟다. 2-Gram 인덱싱 기법은 2글자 단위의 최소 키워드에 대한 키를 관리하는 프론트엔드(Front-end) 인덱스와 2글자 이상의 키워드 묶음(n-SubSequence Window)을 관리하는 백엔드(Back-end)인덱스 2개로 구성된다. 인덱스 생성 과정은 다음과 같다. 첫 번째 단계로, 문서의 본문을 2글자보다 큰 크기로 블록을 구분해서 백엔드 인덱스를 생성 두 번째 단계로, 백엔드 인덱스의 키워드들을 2글자씩 잘라서 프론트엔드 인덱스를 생성 인덱스의 검색 과정은 전문 인덱스의 생성과는 반대로, 입력된 검색어를 2바이트 단위로 동일하게 잘라서 프론트엔드 인덱스를 검색한다. 그 결과를 대상 후보군으로 선정하고, 백엔드 인덱스를 통해 최종 검증을 거쳐 일치하는 결과를 가져온다. 5.7.2 구분자와 N-그램의 차이실제 사용자가 보는 구분자와 N그램의 검색 결과를 보자. 구분자 방식은 검색할 때 왼쪽 일치 기준으로 비교 검색을 실행한다. 그래서 검색단어의 왼쪽에 다른글자가 같이 있으면 검색이 안된다. 예를 들면 “아이폰”을 검색하면 “애플아이폰” 이 검색되지 않는다. 하지만 N그램은 모든 데이터에 대해 무작위로 2바이트씩 인덱스를 생성하므로 검색이 가능하다. 5.7.3 전문 검색 인덱스의 가용성전문 검색 인덱스를 사용하려면 반드시 그에 맞는 구문을 사용해야 한다. 1select * from tb_test where doc_body like '%애플%'; 위와같은 구문은 원하는 검색을 찾을 수 있지만, 효율적으로 쿼리가 실행된 것이 아니라 테이블을 처음부터 끝까지 읽는 풀 테이블 스캔으로 쿼리를 처리한다. 전문 검색 인덱스를 사용하려면 MATCH() AGAINST() 구문으로 검색쿼리를 작성해야 하며, MATCH 절의 괄호에 포함되는 내용은 반드시 사용할 전문 검색 인덱스에 정의된 칼럼이 모두 명시돼야 한다. 5.8 비트맵 인덱스와 함수 기반 인덱스Mysql 스토리지 엔진 가운데 비트맵 인덱스와 함수 기반 (Function based) 인덱스를 지원하는 스토리지 엔진은 없다. 비트 맵 인덱스에 대한 대안은 없지만 함수 기반의 인덱스는 쉽게 우회해서 구현할 수 있다. 테이블에 함수의 결과 값을 저장하기 위한 칼럼을 추가하고, 그 칼럼에 인덱스를 생성해서 사용하면 된다. 5.9 클러스터링 인덱스클러스터란 여러 개를 하나로 묶는다는 의미로 주로 사용되는데, 지금 설명하고자 하는 인덱스의 클러스터링도 그 의미를 크게 벗어나지 않는다. 인덱스에서 클러스터링은 값이 비슷한 것들을 묶어서 저장하는 형태로 구현되는데, 이는 주로 비슷한 값들을 동시에 조회하는 경우가 많다는 점에 착안한것이다. 5.9.1 클러스터링 인덱스클러스터링 인덱스는 테이블의 프라이머리 키에 대해서만 적용되는 내용이다. 즉 프라이머리 키 값이 비슷한 레코드끼리 묶어서 저장하는 것을 클러스터링 인덱스라고 표현한다. 여기서 중요한 것은 프라이머리 키 값에 의해 레코드의 저장 위치가 결정된다는 것이다. 또한 프라이머리 키 값이 변경된다면 그 레코드의 물리적인 저장 위치가 바뀌어야 한다는 것을 의미하기도 한다. 프라이머리 키 값으로 클러스터링된 테이블은 프라이머리 키 값 자체에 대한 의존도가 상당히 크기 때문에 신중히 PK를 결정해야 한다. 클러스터링 인덱스는 프라이머리 키 값에 의해 레코드의 저장 위치가 결정되므로 사실 인덱스 알고리즘이라기 보다 테이블 레코드의 저장 방식이라고 볼 수도 있다. 그래서 “클러스터링 인덱스”와 “클러스터링 테이블”은 동의어로 사용되기도 한다. 클러스터링 인덱스의 구조는 B-Tree와 많이 닮았지만 클러스터링 인덱스의 리프 노드에는 레코드의 모든 칼럼이 같이 저장돼 있다. 즉 클러스터링 테이블은 그 자체 하나의 거대한 인덱스 구조로 관리되는 것이다. PK가 없는 경우는 다음의 우선순위대로 PK를 대체할 칼럼을 선택한다. PK가 있으면 기본적으로 PK를 클러스터 키로 선택 NOT NULL 옵션의 유니크 인덱스(UNIQUE INDEX) 중에서 첫 번째 인덱스를 클러스터 키로 선택 자동으로 유니크한 값을 가지도록 증가되는 칼럼을 내부적으로 추가한 후, 클러스터 키로 선택 5.9.2 보조 인덱스(Secondary index)에 미치는 영향PK가 보조 인덱스에 미치는 영향을 알아보자. MyISAM이나 MEMORY테이블과 같은 클러스터링 되지 않은 테이블은 Insert 될 때 한번 저장된 공간에서 절대 이동하지 않는다. MyISAM 테이블이나 MEMORY 테이블에서는 PK와 보조 인덱스는 구조적으로 아무 차이가 없다. 하지만 InnoDB 테이블의 모든 보조 인덱스는 해당 레코드가 저장된 주소가 아니라 PK값을 저장하도록 구현돼 있다. 5.9.3 클러스터 인덱스의 장점과 단점 장점 PK로 검색할 때 처리 성능이 매우 빠름 테이블의 모든 보조 인덱스가 PK를 가지고 있기 때문에 인덱스만으로 처리될 수 있는 경우가 많음 단점 테이블의 모든 보조 인덱스가 클러스터 키를 갖기 때문에 클러스터 키값의 크기가 클 경우 전체적으로 인덱스의 크기가 커짐 보조 인덱스를 통해 검색할 때 PK로 다시 한번 검색해야 하므로 처리 성능이 조금 느림 Insert 할 때 PK에 의해 레코드의 저장 뒤치가 결정되기 때문에 성능이 느림 PK를 변경할 때 레코드를 Delete하고 Insert하는 작업이 필요하기 때문에 처리 성능이 느림 5.9.4 클러스터 테이블 사용 시 주의사항MyISAM과 같이 클러스터링되지 않은 테이블에 비해 InnoDB에서는 조금 더 주의해야 할 사항이 있다. 클러스터 인덱스 키의 크기클러스터 테이블의 경우, 모든 보조 인덱스가 PK값을 포함한다. 그래서 PK의 크기가 커ㅣ면 보조 인덱스도 크키가 커진다. 하지만 일반적으로 테이블에 보조 인덱스가 4~5개 정도 생성된다는 것을 고려하면 보조 인덱스 크기는 급격히 증가한다. PK는 AUTO-Increment 보다는 업무적인 칼럼으로 생성할 것(가능한 경우) PK는 반드시 명시할 것 Auto-Increment 칼럼을 인조 식별자로 사용할 경우 5.10 유니크 인덱스유니크 인덱스는 사실 인덱스라기 보다는 제약조건에 가깝다. 말 그대로 테이블이나 인덱스에 같은 값이 2개 이상 저장될 수 없음을 의미하는데, Mysql에서는 인덱스 없이 유니크 제약만 설정할 방법이 없다. 5.10.1 유니크 인덱스와 일반 보조 인덱스의 비교유니크 인덱스와 유니크하지 않은 일반 보조 인덱스는 사실 인덱스의 구조상 아무런 차이점이 없다. 유니크 인덱스와 일반 보조 인덱스의 읽기와 쓰기를 성능 관점에서 한번 살펴보자 인덱스 읽기 많은 사람들이 유니크 인덱스가 빠르다고 생각하지만 사실은 그렇지 않다. 유니크하지 않은 보조 인덱스에서 한번 더 해야 하는 작업은 디스크 읽기가 아니라 CPU에서 칼럼값을 비교하는 작업이기 때문에 이는 성능상의 영향이 거의 없다고 볼 수 있다. 유니크하지 않은 보조 인덱스는 중복된 값이 허용되므로 읽어야 할 레코드가 많아서 느린 것이지, 인덱스 자체의 특성 때문에 느린 것이 아니라는 것이다. 인덱스 쓰기 새로운 레코드가 Insert되거나 인덱스 칼럼의 값이 변경되는 경우에는 인덱스 쓰기 작업이 필요하다. 그런데 유니크 인덱스의 키값을 쓸때는 중복된 값이 있는지 없는지 체크하는 과정이 한 단계 더 필요하다. 그래서 일반 보조 인덱스의 쓰기보다 느리다. 그런데 Mysql에서는 유니크 인덱스에서 중복된 값을 체크할 때는 읽기 잠금을 사용하고, 쓰기를 할 때는 쓰기 잠금을 사용하는데 이 과정에서 데드락이 아주 빈번하게 발생한다. InnoDB 스토리지 엔진에서는 인덱스 키의 저장을 버퍼링하기 위해 인서트 버퍼가 사용된다. 그리서 인덱스의 저장이나 변경 작업이 상당히 빨리 처리되지만 안타깝게도 유니크 인덱스는 반드시 중복 체크를 해야 하므로 작업 자체를 버퍼링하지 못한다. 이 때문에 유니크 인덱스는 일반 보조 인덱스보다 더 느려진다. 5.10.2 유니크 인덱스 사용 시 주의사항유일성이 꼭 보장돼야 하는 칼럼에 대해서는 유니크 인덱스를 생성하되, 꼭 필요하지 않다면 유니크 인덱스보다는 유니크하지 않은 보조 인덱스를 생성하는 방법도 한 번씩 고려해 보자. 5.11 외래키Mysql에서 외래키는 InnoDB 스토리지 엔진에서만 생성할 수 있으며, 외래키 제약이 설정되면 자동으로 연관되는 테이블의 칼럼에 인덱스까지 생성된다. 외래키가 제거되지 않은 상태에서는 자동으로 생성된 인덱스를 삭제할 수 없다. InnoDB의 외래키 관리에는 중요한 두 가지 특징이 있다. 테이블의 변경(쓰기 잠금)이 발생하는 경우에만 잠금 경합(잠금 대기)이 발생한다. 외래키와 연관되지 않은 칼럼의 변경은 최대한 잠금 경합(잠금 대기)을 발생시키지 않는다. 5.11.1 자식 테이블의 변경이 대기하는 경우자식 테이블의 외래키 칼럼의 변경은 부모 테이블의 확인이 필요한데, 이 상태에서 부모 테이블의 해당 레코드가 쓰기 잠금이 걸려 잇으면 해당 쓰기 잠금이 해제될 때까지 기다리게 되는 것이다. 이것이 InnoDB의 외래키 관리의 첫 번째 특징에 해당한다. 만약 자식 테이블의 외래키가 아닌 칼럼의 변경은 외래키로 인한 잠금 확장이 발생하지 않는다. 이는 InnoDB의 외래키의 두 번째 특징에 해당한다. 5.11.2 부모 테이블의 변경 작업이 대기하는 경우","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"index","slug":"index","permalink":"https://jumpegg.github.io/tags/index/"}]},{"title":"CH 5 인덱스(5.4, 5.5, 5.6)","slug":"mysql-index3","date":"2017-07-22T13:57:47.000Z","updated":"2017-07-22T15:16:33.170Z","comments":true,"path":"2017/07/22/mysql-index3/","link":"","permalink":"https://jumpegg.github.io/2017/07/22/mysql-index3/","excerpt":"","text":"5.4 해시(Hash) 인덱스5.4.1 구조 및 특성해시 인덱스의 큰 장점은 실제 키값과는 관계없이 인덱스 크기가 작고 검색이 빠르다는 것이다. 해시 인덱스는 트리 형태의 구조가 아니므로 검색하고자 하는 값을 주면 해시 함수를 거쳐서 찾고자 하는 키값이 포함된 버킷을 알아낼 수 있다. 그리고 그 버킷 하나만 읽어서 비교해 보면 실제 레코드가 저장된 위치를 바로 알 수 있다. 또한 해시 인덱스는 원래의 키값을 저장하는 것이 아니라 해시 함수의 결과만을 저장하므로 키 칼럼의 값이 아무리 길어도 실제 해시 인덱스에 저장되는 값은 4~8바이트 수준으로 상당히 줄어든다. 그래서 해시 인덱스는 B-Tree 인덱스보다는 상당히 크기가 작은 편이다. 해시 인덱스에서 가장 중요한 것은 해시 함수로, 입력된 키값이 어디에 저장될지를 결정하는 함수다. 해시함수의 결과 값의 범위가 넓으면 공간의 낭비가 커지고, 값의 범위가 작으면 충돌이 발생해 인덱스의 장점이 사라진다. 입력 값이 다르지만 해시 값이 같은 경우를 충돌이라고 한다. 5.4.2 해시 인덱스의 가용성 및 효율성해시 인덱스는 빠른 검색을 제공하지만 키값 자체가 변환되어 저장되기 때문에 범위를 검색하거나 원본값 기준으로 정렬할 수 없다. 해시 인덱스는 이렇게 원본 키값이 변환되어 저장되기 때문에 B-Tree와는 달리 어떤 방식으로도 해시 인덱스를 사용하지 못하는 경우도 발생한다. 각 예제를 통해 해시 인덱스의 효율성을 살펴보자 작업 범위 제한조건으로 해시 인덱스를 사용하는 쿼리 동등 비교조건으로 값을 검색하거나 IN 연산자를 통한 검색은 해시 인덱스의 장점을 이용할 수 있다. 해시 인덱스를 전혀 사용하지 못하는 쿼리 크다 작다 기반의 검색은 어떠한 방법으로도 해시 인덱스를 사용할 수 없다. 즉 작업 범위 결정 조건뿐 아니라 체크 조건의 용도로도 전혀 사용할 수 없다. 대체로 범위 비교나 부정형 비교는 해시 인덱스를 사용할 수 없다. 5.5 R-Tree 인덱스Mysql의 공간 인덱스(Spatial Index)는 R-Tree 인덱스 알고리즘을 이용해 2차원의 데이터를 인덱싱 하고 검색하는 목적의 인덱스다.기본적인 내부 매커니즘은 B-Tree와 흡사하다. B-Tree는 인덱스를 구성하는 칼럼의 값이 1차원의 스칼라 값인 반면, R-Tree 인덱스는 2차원의 공간 개념 값이라는 것이다. Mysql의 공간 확장에는 아래와 같이 크게 3가지 기능이 포함되 있다. 공간 데이터를 저장할 수 있는 데이터 타입 공간 데이터의 검색을 위한 공간 인덱스(R-Tree 알고리즘) 공간 데이터의 연산 함수(거리 또는 포함 관계의 처리) 5.5.1 구조 및 특성공간 정보의 검색을 위한 R-Tree알고리즘을 이해하려면 MBR이라는 개념을 알고 있어야 한다. MBR 이란 Minimum Bounding Rectangle의 약자로 해당 도형을 감싸는 최소 크기의 사각형을 의미하는데, 이 사각형들의 포함관계를 B-Tree혀테로 구현한 인덱스가 R-Tree 인덱스다. 5.5.2 R-Tree 인덱스의 용도R-Tree는 위에서 언급한 MBR 정보를 이용해 B-Tree 형태로 인덱스를 구축하므로 Rectangle 의 “R”과 B-Tree의 “Tree”를 섞어서 R-Tree라는 이름이 붙여졌으며, 공간 인덱스라고도 한다. 일반적으로 WGS84(GPS)기준의 위도, 경도 좌표 저장에 주로 사용된다. 하지만 위도, 경도 좌표뿐 아니라 CAD/CAM 소프트웨어 또는 회로 디자인 등과 같이 좌표 시스템에 기반을 둔 정보에 대해서는 모두 적용할 수 있다. R-Tree는 도형의 포함관계를 이용하므로 Contains() 또는 Intersect() 등과 같은 포함 관계를 비교하는 함수로 검색을 수행하는 경우에만 인덱스를 이용할 수 있다. 5.6 Fractal-Tree 인덱스인터넷이 발전하면서 데이터의 양이 급증하고 있는데, 하드웨어 성능은 그만큼 따라가지 못하고 있다. 하드웨어 뿐만 아니라 DBMS의 B-Tree 인덱스 알고리즘 또한 한계에 도달한 것으로 보인다. Fractal-Tree는 아주 최근에 개발된 기술인데, 안타깝게도 독점적인 특허로 등록된 알고리즘이어서 아직 많은 DBMS에 구현되지 못하고 있다. 현재는 TokuTek회사에서 개발된 Mysql 스토리지 엔진 TokuDB에만 적용되 있다. 5.6.1 Fractal-Tree의 특성B-Tree인덱스에서 인덱스 키를 검색하거나 변경하는 과정 중에 발생하는 가장 큰 문제는 디스크의 랜덤 I/O가 상대적으로 많이 필요하다는 것이다. Fractal-Tree는 이러한 B-Tree의 단점을 최소화 하고, 이를 순차 I/O로 변환해서 처리할 수 있다는 것이 가장 큰 장점이다. 그래서 Fractal-Tree를 스트리밍 B-Tree라고도 한다. Fractal-Tree는 인덱스 키가 추가되거나 삭제될 때 B-Tree인덱스 보다 더 많은 정렬 작업이 필요로 하며, 이때문에 더 많은 CPU 처리가 필요하다. 하지만 인덱스 단편화가 발생하지 않도록 구성할 수 있고, 인덱스 키 값을 클러스터링 하기 때문에 B-Tree보다는 대용량 테이블에서 높은 성능을 보장한다. 5.6.2 Fractal-Tree의 가용성과 효율성Fractal-Tree의 또 다른 장점은 B-Tree의 장점을 그대로 Fractal-Tree도 가지고 있다는 것이다. 그래서 현재 B-Tree로 생성된 인덱스를 Fractal-Tree로 변경해도 충분히 동일한 효과를 얻을 수 있다. 또한 B-Tree에서 인덱스를 효율적으로 사용하지 못하는 쿼리는 Fractal-Tree에서 적용되더라도 같은 결과를 보인다고 할 수 있기 때문에 별도의 학습이 필요하지 않은 것도 큰 장점이라 볼 수 있다.","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"index","slug":"index","permalink":"https://jumpegg.github.io/tags/index/"}]},{"title":"CH 5 인덱스(5.3)","slug":"mysql-index2","date":"2017-07-22T05:13:23.000Z","updated":"2017-07-22T09:48:09.153Z","comments":true,"path":"2017/07/22/mysql-index2/","link":"","permalink":"https://jumpegg.github.io/2017/07/22/mysql-index2/","excerpt":"","text":"5.3 B-Tree 인덱스B-Tree 의 B는 Balanced 를 의미한다. B-Tree는 칼럼의 원래 값을 변형시키지 않고 인덱스 구조체 내에서는 항상 정렬된 상태로 유지하고 있다. 5.3.1 구조 및 특성B-Tree는 트리 구조의 최상위에 하나의 루트 노드 가 존재하고 그 하위에 자식 노드가 붙어있는 형태다. 트리 구조의 가장 하위에 있는 노드를 리프 노드라 하고, 트리 구조에서 루트 노드도 아니고 리프 노드도 아닌 중간의 노드를 브랜치 노드라고 한다. 데이터베이스에서 인덱스와 실제 데이터가 저장된 데이터는 따로 관리되는데, 인덱스의 리프 노드는 항상 실제 데이터 레코드를 찾아가기 위한 주소 값을 가지고있다. 인덱스의 키값은 모두 정렬되어 있지만 데이터 파일의 레코드는 정렬되어 있지 않다. 레코드 생성시 insert된 순서대로 저장되어 있다고 생각하기 쉽지만, 일반적으로 DBMS는 레코드가 삭제된 공간을 재활용 하므로 순서대로 되어있지 않다. 인덱스는 테이블의 키 칼럼만 가지고 있으므로 나머지 칼럼을 읽으려면 데이터 파일에서 해당 레코드를 찾아야 한다. 이를 위해 인덱스의 리프 노드는 데이터 파일에 저장된 레코드의 주소를 가지게 된다. 5.3.2 B-Tree 인덱스 키 추가 및 삭제인덱스 키 추가새로운 키 값이 B-Tree에 저장될 때 테이블의 스토리지 엔진에 따라 새로운 키값이 즉시 인덱스에 저장될 수도 있고 그렇지 않을 수도 있다. B-Tree에 저장될 때는 저장될 키값을 이용해 B-Tree상의 적절한 위치를 검색해야 한다. 저장될 위치가 결정되면 레코드의 키값과 대상 레코드의 주소 정보를 B-Tree의 리프 노드에 저장한다. 만약 리프 노드가 꽉 차서 더는 저장할 수 없을 때는 리프 노드가 분리되야 하는데, 이는 상위 브랜치 노드까지 처리의 범위가 넓어진다. 이러한 작업 탓에 B-Tree는 상대적으로 쓰기 작업(새로운 키를 추가하는 작업)에 비용이 많이 드는 것으로 알려졌다. 새로운 인덱스 추가 작업에 대한 비용은 대략적으로 계산이 가능하다. 테이블에 레코드를 추가하는 작업 비용을 1이라고 가정하면 해당 테이블의 인덱스에 키를 추가하는 작업 비용을 1~1.5 정도로 예측하는것이 일반적이다. 하지만 여기서 주의해야 할 점은 작업 비용이 CPU에서 들어가는 비용이 아니라 디스크에서 이루어 지기 때문에 시간이 오래걸린다는 점이다. MyISAM스토리지 엔진은 “delay-key-write” 파라메터를 설정해 인덱스 키 추가 작업을 미뤄서 처리할 수 있는데, 이는 동시작업에 적합하지 않다. InnoDB 스토리지 엔진은 키를 추가하는 작업을 조금 더 효율적으로 처리하는데, 상황에 따라 인덱스 키 추가적업을 지연시킬지 바로처리할지를 결정한다. 그 과정은 다음과 같다. 사용자의 쿼리 실행 InnoDB의 버퍼 풀에 새로운 키 값을 추가해야 할 페이지가 존재한다면 즉시 키 추가 작업 처리 버퍼 풀에 B-Tree의 리프 노드가 없다면 인서트 버퍼에 추가할 키값과 레코드의 주소를 임시로 기록해 두고 작업 완료 백그라운드 작업으로 인덱스 페이지를 읽을 때마다 인서트 버퍼에 머지해야 할 인덱스 키값이 있는지 확인한 후, 있다면 병합함 데이터베이스 서버 자원의 여유가 생기면 Mysql 서버의 인서트 버퍼 머지 스레드가 조금씩 인서트 버퍼에 임시 저장된 인덱스 키와 주소 값을 머지시킴 인덱스 키 삭제B-Tree의 키값이 삭제되는 작업은 간단하다. B-Tree에 저장된 키 값을 찾아 삭제 마크를 남긴다. 인덱스 키 변경B-Tree의 키 값의 변경작업은 먼저 키값을 삭제한 후, 다시 새로운 키값을 추가하는 형태로 처리된다. 인덱스 키 검색인덱스를 구축하는 이유는 바로 빠른 검색을 위해서다. B-Tree 인덱스를 이용한 검색은 100% 일치 또는 값의 앞부분(Left-most part)만 일치하는 경우에 사용할 수 있다. 부등호 비교나 값의 뒷부분이 일치하는 경우에는 B-Tree인덱스를 이용한 검색이 불가능하다. 또한 인덱스를 이용한 검색에서 중요한 사실은 인덱스의 키값에 변형이 가해진 후 비교되는 경우에는 절대 B-Tree의 빠른 검색 기능을 사용할 수 없다는것이다. 5.3.3 B-Tree 인덱스 사용에 영향을 미치는 요소인덱스 키값의 크기InnoDB 엔진은 디스크에 데이터를 저장하는 가장 기본 단위 페이지(Page) 또는 블록이라고 하며, 디스크의 모든 읽기 쓰기의 기본단위가 된다. 인덱스도 페이지 단위로 관리되며, B-Tree의 브랜치, 리프 노드를 구분한 기준이 바로 페이지 단위이다. 이진(Binary) 트리는 각 노드가 자식 노드를 2개만 가지는데 B-Tree가 이진트리라면 인덱스 검색이 상당히 비효율적일 것이다. 일반적으로 DBMS의 B-Tree는 자식 노드의 개수가 가변적인 구조이다. B-Tree의 자식 노드의 갯수는 인덱스의 페이지 크기와 키 값의 크기에 따라 결정된다. 만약 인덱스의 키가 16바이트고 InnoDB의 페이지 크기가 16KB이면 인덱스 키 16바이트와 자식노드 정보 12바이트를 추가시켜서 계산하면 16*1024/(16+12) = 585 개 저장 가능하다. 인덱스 키 값이 커지면 디스크로 부터 읽어야 하는 횟수가 늘어나고, 그만큼 느려진다는 것을 의미한다. 또한 인덱스 키 값의 길이가 길어지면 인덱스를 캐시해 두는 버퍼 풀에 캐시할 수 있는 레코드 수가 줄어들게 되므로 메모리의 효율이 떨어지게 된다. B-Tree 깊이인덱스의 키 값이 늘어나면 B-Tree의 깊이가 3인 경우, 키값이 16바이트 일때 최대 2억(585 x 585 x 585)개 정도의 키값을 담을 수 있지만 키값이 32바이트로 늘어나면 5천만(372 x 372 x 372)개로 줄어든다. B-Tree의 깊이는 검색수행시 디스크를 몇번이나 랜덤하게 읽어야 하는지와 직결되는 문제이므로 인덱스의 키 값이 커지면 디스크 읽기 작업이 많아진다. 선택도(기수성)인덱스에서 선택도(Selectivity) 또는 기수성(Cardinality)은 거의 같은 의미로 사용되며, 모든 인덱스키값 가운데 유니크한 값의 수를 의미한다. 전체 인덱스 키값은 100개인데, 그중에서 유니크한 값의 수는 10개라면 기수성은 10이다. 인덱스는 선택도가 높을수록 검색 대상이 줄어들기 때문에 그만큼 빠르게 처리된다. 칼럼의 유니크값과 검색 효율에 대한 예를 들어보겟다 12345CREATE TABLE tb_city( country VARCHAR(10), city VARCHAR(10), INDEX ix_country (country)); 위와같은 테이블을 만들고 다음과 같은 상황을 가정하자 tb_city 에는 1만건의 레코드 존재 각 국가와 도시가 중복되어 저장되있지 않음 그리고 다음과 같은 쿼리를 실행해보자 1select * from tb_test where country='korea' and city='seoul'; country의 유니크 값이 10개country 칼럼의 유니크 값이 10개 이므로 10000/10 해서 1000개 정도의 값이 일치하리라 예측된다. 하지만 검색된 1000건 가운데 city=’seoul’은 1건이므로 999건은 불필요하게 읽은 것으로 볼 수 있다. country의 유니크 값이 1000개country 칼럼의 유니크 값이 10개 이므로 10개 정도의 값이 예측되며 해당하는 레코드는 1개 이므로 9건이 불필요하게 읽어졌다. 이처럼 인덱스에서 유니크한 값의 개수는 인덱스나 쿼리의 효율성에 큰 영향을 미치게 된다. 읽어야 하는 레코드의 건수인덱스를 통해 테이블의 레코드를 읽는 것은 인덱스를 거치지 않고 바로 테이블의 레코드를 읽는 것보다 높은 비용이 드는 작업이다. 인덱스를 이용한 읽기의 손익 분기점을 판단할 필요가 있는데, 일반적인 DBMS의 옵티마이저에서는 인덱스를 통해 레코드 1건을 읽는 것이 테이블에서 직접 레코드 1건을 읽는 것보다 4~5배 정도 더 비용이 많이 드는 작업인 것으로 예측한다. 즉, 인덱스를 통해 읽어야 할 레코드의 건수가 전체 테이블 레코드의 20~25%를 넘어서면 인덱스를 이용하지 않고 직접 테이블을 모두 읽어서 필요한 레코드만 가려내는 방식으로 처리하는 것이 효율적이다. 손익 분기점인 20~25%를 넘어서는 경우 옵티마이저는 인덱스를 이용하지 않고 직접 테이블을 처음부터 끝까지 읽어서 처리할 것이다. 5.3.4 B-Tree 인덱스를 통한 데이터 읽기인덱스 레인지 스캔인덱스 레인지 스캔은 검색해야 할 인덱스의 범위가 결정됐을 때 사용하는 방식이다. 루트노드에서 부터 비교를 시작해 브랜치 노드를 거치고 최종적으로 리프 노드까지 찾아 들어가서 시작지점을 찾는다. 시작위치부터 리프노드의 레코드만 순서대로 읽는다. 스캔하다가 리프 노드의 끝까지 읽으면 리프 노드 간의 링크를 이용해 다음 리프 노드를 찾아서 다시 스캔한다. 그리고 최종적으로 스캔을 멈춰야 할 위치에 다다르면 지금까지 읽은 레코드를 반환한다. 인덱스를 스캔하는 방향과는 상관없이 해당 인덱스를 구성하는 칼럼의 정순 또는 역순으로 정렬된 상태의 레코드를 가져온다. 이는 별도의 정렬 과정이 수반되는 것이 아니라 인덱스 자체의 정렬 특성 때문에 자동으로 그렇게 된다. 인덱스의 검색 조건에 해당하는 건들은 데이터 파일에서 레코드를 읽어오는 과정이 필요하다. 그래서 검색된 레코드 건수 만큼 랜덤I/O가 실행 되는데 이 작업은 비용이 많이드는 관계로 인덱스 사용 여부에 영향을 미친다. 인덱스 풀 스캔일반적으로 인덱스의 크기는 테이블의 크기보다 작으므로 직접 테이블을 처음부터 끝까지 읽는 것보다는 인덱스만 읽는 것이 효율적이다. 쿼리가 인덱스에 명시된 칼럼만으로 조건을 처리할 수 있는 경우 주로 이 방식이 사용된다. 인덱스 뿐만 아니라 데이터 레코드까지 모두 읽어야 한다면 절대 이 방식으로 처리되지 않는다. 인덱스에 포함된 칼럼만으로 쿼리를 처리할 경우 테이블의 레코드를 읽을 필요가 없다. 인덱스의 전체 크기는 테이블 자체의 크기보다 훨씬 작으므로 인덱스 풀 스캔은 테이블 전체를 읽는 것보다는 적은 디스크 I/O로 쿼리를 처리할 수 있다. 루스 인덱스 스캔루스 인덱스 스캔은 말 그대로 느슨하게 듬성듬성 인덱스를 읽는 것을 말한다. 루스 인덱스 스캔은 인덱스 레인지 스캔과 비슷하게 작동하지만, 중간마다 필요치 않은 인덱스 키값은 무시하고 다음으로 넘어가는 형태로 처리한다. 일반적으로 Group by 또는 집합 함수 가운데 Max(), Min() 함수에 대해 최적화 하는 경우에 사용된다. 5.3.5 다중 칼럼(Multi-column) 인덱스인덱스가 다중으로 설정되어 있을 때 인덱스 구성은 첫번째 칼럼에 의존해서 정렬되어 있다. 다중 칼럼 인덱스에서 인덱스 내에 각 칼럼의 위치가 상당히 중요하며, 신중히 결정해야 하는 이유는 인덱스 순서에 따른 컬럼 정렬이 바뀌기 때문이다. B-Tree 인덱스의 정렬 및 스캔 방향인덱스의 정렬일반적으로 DBMS에서는 인덱스를 생성하는 시점에 인덱스를 구성하는 각 칼럼의 정렬을 설정할 수 있다. 인덱스의 모든 칼럼을 오름차순 또는 내림차순으로만 생성하는 것은 아무런 문제가 되지 않는다. 하지만 가끔 인덱스를 구성하는 칼럼 가운데 오름차순과 내림차순을 혼합해서 만들어야 할 때가 있다. Mysql에서는 칼럼의 값을 역으로 변환해서 구현하는 것이 유일한 방법이다. 인덱스의 스캔 방향인덱스는 항상 오름차순으로만 정렬돼 있지만 인덱스를 최소값부터 읽으면 오름차순으로 값을 가져올 수 있고, 최댓값부터 거꾸로 읽으면 내림차순으로 값을 가져올 수 있다는 것을 옵티마이저는 알고있다. 인덱스를 역순으로 정렬되게 할 수는 없지만 인덱스를 읽는 방향에 따라 오름차순 또는 내림차순 정렬 효과를 얻을 수 있다. 인덱스를 오름차순으로 일그면 최종적으로 출력되는 결과 레코드는 자동으로 오름차순으로 정렬된 결과이며, 내림차순으로 읽으면 그 결과는 내림차순으로 정렬된 상태가 되는 것이다. 쿼리의 order by 처리나 min(), max() 함수 등의 최적화가 필요한 경우, mysql 옵티마이저는 인덱스의 읽기 방향을 전환해서 사용하도록 실행 계획을 만들어 낸다. 5.3.7 B-Tree 인덱스의 가용성과 효율성여기서는 어떤 조건에서 인덱스를 사용할 수 있고 없는지, 또한 일부만 이용하게 되는지도 함께 살펴보겟다. 비교 조건의 종류와 효율성다중 칼럼 인덱스에서 각 칼럼의 순서와 그 칼럼에 사용된 조건이 동등비교인지 아니면 범위조건인지에 따라 각 인덱스 칼럼의 활용 형태가 달라진다. 다음과같은 예를 들어보자 테이블 dept_emp 는 dept_no 와 emp_no 가 인덱스로 설정되어 있다. 케이스 A : dept_no + emp_no 케이스 B : emp_no + dept_no 그리고 다음과 같은 쿼리를 날려보자 12select * from dept_empwhere dept_no='d002' and emp_no &gt;= 10114; 케이스 A의 경우 dept_no에 해당하는 레코드를 찾고, 그 이후에는 dept_no에 해당하는 값이 아닐때 까지 죽 읽기만 하면 된다. 하지만 케이스B는 범위 조건에 맞는 emp_no를 찾고 거기서 dept_no 를 다시 조회해야 한다. 케이스A 에서 두번째 인덱스인 emp_no는 비교 작업의 범위를 좁히는데 도움을 준다. 하지만 케이스B 에서 emp_no는 비교작업의 범위를 좁히는데 아무런 도움이 되지 않는다. 공식적인 명칭은 아니지만 케이스A같이 작업의 범위를 결정하는 조건을 “작업 범위 결정 조건”이라 하고, 케이스B 처럼 작업 범위를 좁히지 못하고 단순히 거름종이 역할만을 하는 것을 “필터링 조건” 또는 “체크 조건” 이라고 표현한다. 인덱스의 가용성B-Tree 인덱스의 특징은 왼쪽 값에 기준해서 오른쪽 값이 정렬돼 있다는 것이다. 여기서 왼쪽이라 함은 하나의 칼럼 내에서뿐만 아니라 다중 칼럼 인덱스의 칼럼에 대해서도 함께 적용된다. 케이스 A : Index(first_name) 케이스 B : Index(dept_no, emp_no) 하나의 칼럼으로 검색할 경우 값의 왼쪽부분이 없으면 인덱스 레인지 스캔 방식의 검색이 불가능하다. 또한 다중 칼럼 인덱스에서도 왼쪽 칼럼의 값을 모르면 인덱스 레인지 스캔을 사용할 수 없다. 케이스 A 1select * from employees where first_name like '%mer'; 위 쿼리는 인덱스 레인지 스캔 방식으로 인덱스를 이용할 수 없다. 그 이유는 검색 칼럼의 가장 첫 글자를 비교해야 하는데 처음값이 고정되지 않았기 때문이다. 케이스 B 1select * from dept_emp where emp_no&gt;=10144; 인덱스가 dept_no를 기준으로 정렬되어 있는데 emp_no만으로 검색을 하면 효율적인 검색이 되질 않는다. 가용성과 효율성 판단기본적으로 B-Tree 인덱스의 특성상 다음 조건에서는 사용할 수 없다. NOT-EQUAL로 비교된 경우(“&lt;&gt;”, “NOT IN”, “NOT BETWEEN”, “IS NOT NULL”) LIKE “%??” (앞부분이 아닌 뒷부분 일치) 형태로 문자열 패턴이 비교된 경우 스토어드 함수나 다른 연산자로 인덱스 칼럼이 변경된 후 비교된 경우 NOT-DETERMINISTIC 속성의 스토어드 함수가 비교 조건에 사용된 경우 데이터 타입이 서로 다른 비교(인덱스 칼럼의 타입을 변환해야 비교가 가능한 경우) 문자열 데이터 타입의 골레이션이 다른 경우 다른 일반적인 DBMS에서는 NULL 값은 인덱스에 저장되지 않지만 MYSQL에서는 NULL 값도 인덱스로 관리된다. 1....where column is null 다중 칼럼으로 만들어진 인덱스는 어떤 조건에서 사용될 수 있고, 어떤 경우에는 절대 사용될 수 없는지 살펴보자. 다음과 같은 인덱스가 있다고 가정해보자. 1index ix_test(col_1, col_2, col_3, ... ,col_n) 작업 범위 결정 조건으로 인덱스를 사용하지 못하는 경우 col_1 칼럼에 대한 조건이 없는경우 col_1 칼럼의 비교 조건이 위의 인덱스 사용불가 조건 중 하나인 경우 작업 범위 결정 조건으로 인덱스를 사용하는 경우(i는 2보다 크고 n보다 작은 임의의 값을 의미) col1~col(i-1) 칼럼까지 equal 형태로(또는 in) 비교 col_i 칼럼에 대해 다음 연산자 중 하나로 비교 equal 크다 작다 형태 like로 좌측 일치 패턴 작업 범위 결정 조건으로 인덱스를 사용하는 쿼리 패턴은 이 밖에도 상당히 많이 있겟지만, 대표적인 것들을 기억해 두면 좀 더 효율적인 쿼리를 쉽게 작성할 수 있을 것이다.","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"index","slug":"index","permalink":"https://jumpegg.github.io/tags/index/"}]},{"title":"CH 5 인덱스(5.1, 5.2)","slug":"mysql-index1","date":"2017-07-21T07:31:24.000Z","updated":"2017-07-22T05:12:48.327Z","comments":true,"path":"2017/07/21/mysql-index1/","link":"","permalink":"https://jumpegg.github.io/2017/07/21/mysql-index1/","excerpt":"","text":"5.1 디스크 읽기 방식5.1.1 저장 매체일반적으로 서버에 사용되는 저장 매체는 크게 3가지로 나뉜다. 내장 디스크(Internal Disk) DAS(Direct Attached Storage) NAS(Network Attached Storage) SAN(Storage Area Network) 내장 디스크는 개인용 PC의 본체 내에 장착된 디스크와 같은 매체다. 이런 내장 디스크는 물리적으로 제한된 공간 때문에 장착할 수 있는 디스크의 개수가 적고 용량이 부족할 때가 많다. 내장 디스크의 용량 문제를 해결하기 위해 주로 사용하는 것이 DAS인데, DAS는 컴퓨터의 본체와는 달리 디스크만 있는 것이 특징이다. DAS는 하나의 컴퓨터 본체에 연결해서 사용하기 때문에 디스크의 정보를 여러 컴퓨터가 동시에 공유하는 것이 불가능하다. 내장 디스크와 DAS의 문제점을 동시에 해결하기 위해 주로 NAS와 SAN을 사용한다. DAS는 내장디스크처럼 SATA나 SAS 또는 SCSI 케이블로 연결되지만, NAS는 TCP/IP를 통해 연결된다. SAN은 DAS로는 구축할 수 없는 아주 대용량의 스토리지 공간을 제공하는 장치다. SAN은 여러 컴퓨터에서 동시에 사용할 수 있을뿐더러 컴퓨터 본체와 광케이블로 연결되기 때문에 상당히 빠르고 안정적인 데이터 처리를 보장해준다. 5.1.2 디스크 드라이브와 솔리드 스테이트 드라이브컴퓨터에서 CPU나 메모리와 같은 주요 장치는 대부분 전자식 장치지만 디스크 드라이브는 기계식 장치다. 그래서 데이터베이스 서버에서는 항상 디스크 장치가 병목 지점이 된다. 이러한 단점을 대체하기 위해 전자식 저장 매체인 SSD가 많이 출시되고 있다. 5.1.3 랜덤 I/O 와 순차 I/O랜덤 I/O라는 표현은 디스크 드라이브의 플래터(원판)을 돌려서 읽어야 할 데이터가 저장된 위치로 디스크 헤더를 이동시킨 다음 데이터를 읽는 것을 의미하는데, 사실 순차 I/O 또한 이 작업은 같다. 디스크에 데이터를 쓰고 읽는 데 걸리는 시간은 디스크 헤더를 움직여서 읽고 쓸 위치로 옮기는 단계에서 결정된다. 순차 I/O의 경우 랜덤 I/O 보다 빠르고, 이렇게 순차적으로 데이터를 처리하기 위해 Mysql서버에서는 작은 데이터의 읽고 쓰는 작업을 그룹 커밋이나 바이너리 로그 버퍼 또는 InnoDB 로그 버퍼 등의 기능이 내장되어 있다. 5.2 인덱스란?DBMS에서 데이터 테이블의 모든 데이터를 검색해서 원하는 결과를 가져오려면 시간이 오래걸린다. 그래서 칼럼의 값과 해당 레코드가 저장된 주소를 키와 값의 쌍(Key-Value)으로 인덱스를 만들어 둔다. 데이터를 찾을 때 국어사전처럼 “ㄱ”,”ㄴ” 같이 일정한 기준으로 인덱스를 나눠놓으면 데이터를 찾을 때 빨리 찾을 수 있다. 인덱스의 또다른 특징을 프로그래밍 언어의 자료구조로 알아보자. 자료구조에는 SortedList 와 ArrayList 라는 자료구조가 있는데 SortedList는 DBMS의 인덱스와 같은 자료구조이며, ArrayList는 데이터 파일과 같은 자료구조를 사용한다. SortedList는 저장되는 값을 항상 정렬된 상태로 유지하는 자료구조이고, ArrayList는 값을 저장되는 순서대로 그대로 유지하는 자료구조다. SortedList는 데이터가 저장될 때마다 항상 값을 정렬해야 하므로 저장되는 과정이 복잡하고 느리지만, 값을 가져올때는 아주 빨리 가져올 수 있다. 인덱스를 설정할 때 인덱스의 갯수만큼 insert, update, delete 작업이 느려지는데 이러한 저장속도의 희생 정도를 감안해서 인덱스를 만들어야한다. 인덱스는 데이터를 관리하는 방식과 중복값의 허용 여부 등에 따라 여러 가지로 나눠볼 수 있다. 인덱스를 역할별로 구분해 본다면 프라이머리 키(Primary key)와 보조 키(Secondary key)로 구분해 볼 수 있다. 프라이머리 키는 그 레코드를 대표하는 칼럼의 값으로 만들어진 인덱스를 의미한다. 이 칼럼은 테이블에서 해당 레코드를 식별할 수 있는 기준값이 되기 때문에 우리는 이를 식별자라고도 부른다. 위의 키를 제외한 모든 인덱스는 보조 인덱스(Secondary Index)로 분류한다. 데이터 저장 방식(알고리즘)별로 구분하는 것은 사실 상당히 많은 분류가 가능하겟지만 대표적으로 B-Tree 인덱스와 Hash 인덱스로 구분할 수 있다. B-Tree 알고리즘은 가장 일반적으로 사용되는 인덱스 알고리즘으로서, 상당히 오래전에 도입된 알고리즘이다. B-Tree인덱스는 칼럼의 값을 변경하지 않고, 원래의 값을 이용해 인덱싱 하는 알고리즘이다. Hash 인덱스 알고리즘은 칼럼의 값으로 해시 값을 계산해서 인덱싱 하는 알고리즘으로, 매우 빠른 검색을 지원한다. 하지만 값을 변형해서 인덱싱하므로, prefix 일치와 같이 값의 일부만 검색하고자 할 때는 해시 인덱스를 사용할 수 없다. Hash 인덱스는 주로 메모리 기반 데이터베이스에서 많이 사용한다. Fractal-Tree 알고리즘은 B-Tree의 단점을 보완하기 위해 고안되었다. 데이터가 저장되고 삭제될 때 처리비용을 줄일 수 있게 설계된것이 특징이다. 데이터의 중복 허용 여부로 분류하면 유니크 인덱스(Unique)와 유니크하지 않은 인덱스(Non-Unique)로 구분할 수 있다. 이 유니크 인덱스는 옵티마이저에게는 상당히 중요한 문제가 된다. 옵티마이저에서 유니크 인덱스에 대해 동등 조건(Equal, =) 으로 검색한다는 것은 항상 1건의 레코드만 찾으면 더 찾지 않아도 된다는 것을 의미한다.","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"index","slug":"index","permalink":"https://jumpegg.github.io/tags/index/"}]},{"title":"Javascript 패턴 - 객체 생성 패턴 3","slug":"pattern-object3","date":"2017-07-20T07:32:30.000Z","updated":"2017-07-20T07:56:27.638Z","comments":true,"path":"2017/07/20/pattern-object3/","link":"","permalink":"https://jumpegg.github.io/2017/07/20/pattern-object3/","excerpt":"","text":"5.4 모듈 패턴자바스크립트는 패키지를 위한 별도의 문법이 없다. 하지만 모듈 패턴을 사용하면 개별적인 코드를 느슨하게 결합시킬 수 있다. 모듈 패턴은 지금까지 살펴본 다음 패턴들 여러 개를 조합한 것이다. 네임스페이스 패턴 즉시 실행 함수 비공개 멤버와 특권 멤버 의존 관계 선언 첫 단계는 네임스페이스를 정하는 것이다. 1MyApp.namespace('MyApp.utilities.array'); 그 다음 단계는 모듈을 정의하는 것이다. 공개 여부를 제한해야 한다면 즉시 실행함수를 사용해 비공개 유효범위를 만들면 된다. 즉시 실행함수는 모듈이 될 객체를 반환한다. 이 객체에는 모듈 사용자에게 제공할 공개 인터페이스가 담기게 될 것이다. 12345MyApp.utilities.array = (function()&#123; return &#123; // 여기에 객체 내용을 구현 &#125;;&#125;()); 이제 공개 인터페이스에 메서드를 추가해보자. 12345678910MyApp.utilities.array = (function()&#123; return &#123; inArray: function(needle, haystack)&#123; // ... &#125;, isArray: function(a)&#123; // ... &#125; &#125;;&#125;());","categories":[{"name":"Javascript Pattern","slug":"Javascript-Pattern","permalink":"https://jumpegg.github.io/categories/Javascript-Pattern/"}],"tags":[{"name":"pattern","slug":"pattern","permalink":"https://jumpegg.github.io/tags/pattern/"}]},{"title":"nginx 파일업로드 문제","slug":"angular2-problem-01","date":"2017-07-20T05:34:59.000Z","updated":"2017-07-20T05:48:45.312Z","comments":true,"path":"2017/07/20/angular2-problem-01/","link":"","permalink":"https://jumpegg.github.io/2017/07/20/angular2-problem-01/","excerpt":"","text":"nginx 파일업로드 제한 문제Angular로 개인 프로젝트로 만든 사이트중 파일 업로드 부분에서 문제가 발생했었다. 문제인식부끄럽게도 면접보러 간 자리에서 파일 업로드에 문제가 발생한것을 발견했다. 그 당시에 확인한 오류 메세지와 혼자 고치면서 보게된 메세지가 달라서 이후에 다른 문제점을 발견할 수도 있는데 일단 지금 확인된 버그부터 수정했다. 원인내가받은 에러메세지는 ‘413 Request Entity Too Large’ 였다. nginx에서 파일업로드 설정이 없으면 용량에 제한이 걸리는듯 했다. 필자는 서버구현 부분에서 용량제한을 걸어놨었고 nginx에는 따로 설정을 하지 않아서 생기는 문제로 인식되었다. 해결nginx의 설정파일에 최대 body사이즈를 설정해준다. nginx가 존재하는 곳을 찾기위해 ‘whereis nginx’ 명령어를 사용했다. 1$ whereis nginx 그리고 vi로 default.conf 파일을 열어 다음 설정을 추가해주었다. 1client_max_body_size 20M; 출처참조 블로그","categories":[{"name":"문제해결","slug":"문제해결","permalink":"https://jumpegg.github.io/categories/문제해결/"}],"tags":[{"name":"nginx 파일업로드","slug":"nginx-파일업로드","permalink":"https://jumpegg.github.io/tags/nginx-파일업로드/"}]},{"title":"Javascript 패턴 - 객체 생성 패턴 2","slug":"pattern-object2","date":"2017-07-18T09:26:22.000Z","updated":"2017-07-20T07:25:59.756Z","comments":true,"path":"2017/07/18/pattern-object2/","link":"","permalink":"https://jumpegg.github.io/2017/07/18/pattern-object2/","excerpt":"","text":"5.3 비공개 프로퍼티와 메서드자바 등 다른 언어와는 달리 자바스크립트에는 private, protected, public 프로퍼티와 메서드를 나타내는 별도의 문법이 없다. 객체의 모든 멤버는 public, 즉 공개되어 있다. 12345678var myobj = &#123; myprop: 1, getProp: function() &#123; return this.myprop; &#125;&#125;console.log(myobj.myprop); // 'myprop'에 공개적으로 접근할 수 있다.console.log(myobj.getProp()); // getProp() 역시 공개되어 있다. 비공개(private) 멤버비공개 멤버에 대한 별도의 문법은 없지만 클로저를 사용해서 구현할 수 있다. 생성자 함수 안에서 클로저를 만들면, 클로저 유효범위 안의 변수는 생성자 함수 외부에 노출되지 않지만 객체의 공개 메서드 안에서는 쓸 수 있다. 123456789101112131415function Gadget()&#123; // 비공개 멤버 var name = 'iPod'; // 공개된 함수 this.getName = function() &#123; return name; &#125;;&#125;var toy = new Gadget();// 'name'은 비공개이므로 undefined가 출력된다.console.log(toy.name); // undefined// 공개 메서드에서는 'name'에 접근할 수 있다.console.log(toy.getName()); 특권 메서드특권 메서드는 비공개 멤버를 외부에서 접근 가능하게 하는 메서드를 말한다. 위에서는 getName()에 해당한다. 비공개 멤버의 허점비공개 멤버를 유지하는게 관건이라면, 다음과 같은 경우에 대해서 신경을 써야 한다. 파이어폭스의 초기 버전 중 일부는 eval() 함수에 두 번째 매개변수를 전달 할 수 있게 되어있다. 이 매개변수는 함수의 비공개 유효범위를 들여다볼 수 있게 해주는 컨텍스트 객체다. 모질라 라이노(Rhino)의 parent 프로퍼티도 이와 비슷한 방식으로 비공개 유효범위에 접근할 수 있게 해준다. 현재 널리 사용되는 브라우저에는 적용되지 않는 사례들이다. 특권 메서드에서 비공개 변수의 값을 바로 반환할 경우 이 변수가 객체나 배열이라면 값이 아닌 참조가 반환되기 때문에, 외부 코드에서 비공개 변수값을 수정할 수 있다. 비공개 멤버에 대한 접근123456789101112function Gadget()&#123; // 비공개 멤버 var specs = &#123; screen_width: 320, screen_height: 480, color: \"white\" &#125;; // 공개 함수 this.getSpecs = function()&#123; return specs; &#125;&#125; 여기서 getSpec() 메서드가 specs 객체에 대한 참조를 반환하는게 문제다. 의도적으로 감춘 specs를 참조를 통해 외부에서 변경이 가능해지게 된 것이다. 의도대로라면 setSpec()메서드를 통해서만 값을 변경 가능하게 작동해야 한다. 이를 해결하기 위해서는 getSpec() 에 객체를 복사해서 반환하는 방식으로 구현을 하면 된다. 이를 ‘최소 권한의 원칙(Principle of Least Authority, POLA)’ 이라고도 한다. 객체 리터럴과 비공개 멤버지금까지는 비공개 멤버를 만드는데 생성자를 사용했다. 그렇다면 객체 리터럴로 만들어진 객체는 비공개 멤버를 구현할 수 있을까? 객체 리터럴에서는 익명 즉시 실행함수 를 추가하여 클로저를 만든다. 다음 예제를 보자. 123456789101112131415var myobj;(function()&#123; // 비공개 멤버 var name = \"my, oh my\"; // 공개될 부분을 구현한다. // var를 사용하지 않았다는데 주의하라. myobj = &#123; // 특권 메서드 getName: function()&#123; return name; &#125; &#125;;&#125;());myobj.getName(); // \"my, oh my\" 다음 예제는 기본 개념은 동일하지만 약간 다르게 구현되어 있다. 앞으로 나올 ‘모듈 패턴’의 기초가 되는 예제이다. 12345678910111213var myobj = (function()&#123; // 비공개 멤버 var name = \"my, oh my\"; // 공개될 부분을 구현한다. return &#123; getName: function()&#123; return name; &#125; &#125;;&#125;());myobj.getName(); // \"my, oh my\" 프로토타입과 비공개 멤버생성자를 사용하여 비공개 멤버를 만들 경우, 생성자를 호출하여 새로운 객체를 만들 때마다 비공개 멤버가 매번 재생성된다는 단점이 있다. 이러한 중복을 없애고 메모리를 절약하려면 공통 프로퍼티와 메서드를 생성자의 prototype 프로퍼티에 추가해야 한다. 이렇게 하면 동일한 생성자로 생성한 모든 인스턴스가 공통된 부분을 공유하게 된다. 감춰진 비공개 멤버들도 모든 인스턴스가 함께 쓸 수 있다. 이를 위해서는 두 가지 패턴, 즉 생성자 함수 내부에 비공개 멤버를 만드는 패턴과 객체 리터럴로 비공개 멤버를 만드는 패턴을 함께 써야한다. 왜냐하면 prototype 프로퍼티도 결국 객체라서, 객체 리터럴로 생성할 수 있기 때문이다. 예제를 보자 1234567891011121314151617181920212223function Gadget()&#123; // 비공개 멤버 var name = 'iPod'; // 공개 함수 this.getName = function()&#123; return name; &#125;;&#125;Gadget.prototype = (function()&#123; // 비공개 멤버 var browser = \"Mobile Webkit\"; // 공개된 프로토타입 멤버 return &#123; getBrowser: function()&#123; return browser; &#125; &#125;;&#125;());var toy = new Gadget();console.log(toy.getName());console.log(toy.getBrowser()); 비공개 함수를 공개 메서드로 노출시키는 방법노출 패턴(revelation pattern)은 비공개 메서드를 구현하면서 동시에 공개 메서드로도 노출하는 것을 말한다. 123456789101112131415161718192021222324252627var myarray;(function()&#123; var astr = \"[object Array]\", var toString = Object.prototype.toString; function isArray(a)&#123; return toString.call(a) === astr; &#125; function indexOf(haystack, needle)&#123; var i = 0, var max = haystack.length; for( ; i &lt; max; i += 1)&#123; if(haystack[i] === needle)&#123; return i; &#125; &#125; return -1; &#125; myarray = &#123; isArray: isArray, indexOf: indexOf, inArray: indexOf &#125;&#125;()); 위의 예제는 객체 리터럴 안에 비공개 멤버를 만드는 패턴에 기반하고 있다. 여기에는 비공개 변수 두 개와 비공개 함수 두개가 존재한다. 즉시 실행함수의 마지막 부분을 보면, 공개적인 접근을 허용해도 괜찮다고 결정한 기능들이 myarray 객체에 채워진다. 새로운 myarray 객체를 테스트 해보자 1234567myarray.isArray([1,2]); // truemyarray.isArray(&#123;0 : 1&#125;); // falsemyarray.indexOf([\"a\", \"b\", \"z\"], \"z\"); // 2myarray.inArray([\"a\", \"b\", \"z\"], \"z\"); // 2myarray.indexOf = null;myarray.inArray([\"a\", \"b\", \"z\"], \"z\"); // 2","categories":[{"name":"Javascript Pattern","slug":"Javascript-Pattern","permalink":"https://jumpegg.github.io/categories/Javascript-Pattern/"}],"tags":[{"name":"pattern","slug":"pattern","permalink":"https://jumpegg.github.io/tags/pattern/"}]},{"title":"Javascript 패턴 - 객체 생성 패턴 1","slug":"pattern-object1","date":"2017-07-18T07:48:25.000Z","updated":"2017-07-18T09:27:13.070Z","comments":true,"path":"2017/07/18/pattern-object1/","link":"","permalink":"https://jumpegg.github.io/2017/07/18/pattern-object1/","excerpt":"","text":"5.1 네임스페이스 패턴네임스페이스 패턴네임스페이스는 프로그램에서 필요로 하는 전역 변수의 개수를 줄이는 동시에 과도한 접두어를 사용하지 않고도 이름이 겹치지 않게 해준다. 이러한 네임스페이스 패턴은 자바스크립트 언어에 내장된 기능은 아니지만 어렵지 않게 구현할 수 있다. 1234567891011121314151617// 전역 객체var myApp = &#123;&#125;;// 생성자myApp.parent = function() &#123;&#125;;myApp.child = function() &#123;&#125;;// 변수myApp.some_var = 1;// 객체 컨테이너myApp.modules = &#123;&#125;;// 객체들을 컨테이너 안에 추가한다.myApp.modules.module1 = &#123;&#125;;myApp.modules.module1.data = &#123;a : 1, b : 2&#125;;myApp.modules.module2 = &#123;&#125;; 먼저 애플리케이션 전역 전용 객체 (위에선 myApp이 전역 전용 객체)를 생성한다. 그런 다음 모든 함수와 변수들을 이 전역 객체의 프로퍼티로 생성한다. 이 패턴은 코드에 네임스페이스를 지정해주며, 코드 내의 이름 충돌 뿐 아니라 이 코드와 같은 페이지에 존재하는 자바스크립트 라이브러리나 위젯 등 서드 파티 코드와의 이름 충돌도 방지해준다. 단점 모든 변수와 함수에 접두어를 붙여야 하기 때문에 전체적으로 코드량이 약간 더 많아지고 따라서 다운로드해야 하는 파일 크기도 늘어난다. 전역 인스턴스가 단 하나뿐이기 때문에 코드의 어느 한 부분이 수정되어도 전역 인스턴스를 수정하게 된다. 즉 나머지 기능들도 갱신된 상태를 물려받는다. 이름이 중첩되고 길어지므로 프로퍼티를 판별하기 위한 검색 작업도 길고 느려진다. 이 장의 뒷부분에서는 이 단점을 해결하기 위한 방법으로는 샌드박스 패턴이 있다. 범용 네임스페이스 함수프로그램의 복잡도가 증가하고 코드의 각 부분들이 별개의 파일로 분리되어 선택적으로 문서에 포함되게 되면, 어떤 코드가 특정 네임스페이스나 그 내부의 프로퍼티를 처음으로 정의한다고 가정하기가 위험하다. 그러므로 네임스페이스를 생성하거나 프로퍼티를 추가하기 전에 먼저 이미 존재하는지 여부를 확인하는 것이 최선이다. 123456// 생성 이전에 존재여부 확인if( typeof myApp === \"undefined\")&#123; var myApp = &#123;&#125;;&#125;// 간략히 줄임var myApp = myApp || &#123;&#125;; 이런 확인작업의 추가는 상당량의 중복 코드를 발생시키므로 네임스페이스를 생성하는 재사용 가능한 함수를 만들어 두는편이 편하다. 12345678910111213141516171819var myApp = myApp || &#123;&#125;;myApp.namespace = function(ns_string)&#123; var parts = ns_string.split('.'), var parent = myApp, var i; if (parts[0] === \"myApp\")&#123; parts = parts.slice(1); &#125; for(i=0; i&lt;parts.length; i+=1)&#123; if(typeof parent[parts[i]] === \"undefined\")&#123; parent[parts[i]] = &#123;&#125;; &#125; parent = parent[parts[i]]; &#125; return parent;&#125;; 이 코드는 다음 모든 예에서 사용할 수 있다.123456789// 반환 값을 지역변수에 할당한다.var module2 = myApp.namespace('myApp.modules.module2');module2 === myApp.modules.module2; // true// 첫 부분의 'myApp'을 생략하고도 쓸 수 있다.myApp.namespace('modules.module51');// 아주 긴 네임스페이스myApp.namespace('once.upon.a.time.there.was.this.long.nested.property'); 5.2 의존 관계 선언자바스크립트 라이브러리들은 대개 네임스페이스를 지정하여 모듈화되어 있기 때문에, 필요한 모듈만 골라서 쓸 수 있다. 예를 들어 YUI2에는 네임스페이스 역할을 하는 YAHOO 라는 전역변수가 있다. 이때 함수나 모듈 내 최상단에, 의존 관계에 있는 모듈을 선언하는 것이 좋다. 즉 지역변수를 만들어 원하는 모듈을 가리키도록 선언하는 것이다. 1234567var myFunction = function() &#123; // 의존관계에 있는 모듈들 var event = YAHOO.util.Event, var dom = YAHOO.util.Dom; // 이제 event와 dom 이라는 변수를 사용한다....&#125; 대단히 간단한 패턴이지만 상당히 많은 장점을 가지고 있다. 의존 관계가 명시적으로 선언되어 있기 때문에 코드를 사용하는 사람이 페이지내에 반드시 포함시켜야 하는 스크립트 파일이 무엇인지 알 수 있다. 함수의 첫머리에 의존 관계가 선언되기 때문에 의존 관계를 찾아내고 이해하기가 쉽다. dom과 같은 지역 변수는 YAHOO와 같은 전역 변수보다 언제나 더 빠르며 YAHOO.util.Dom 처럼 전역 변수의 중첩 프로퍼티와 비교하면 더 말할 것도 없다. 의존 관계 선언 패턴을 잘 지키면 함수 안에서 전역 객체 판별을 단 한번만 수행하고, 이 다음부터는 지역 변수를 사용하기 때문에 훨씬 빠르다. YUI 컴프레서나 구글 클로저 등 고급 압축 도구는 지역 변수명에 대해서는 event를 A 라는 글자 하나로 바꾸는 식으로 축약해 코드를 줄여준다. 하지만 전역 변수명 변경은 위험하기 때문에 축약하지 않는다.","categories":[{"name":"Javascript Pattern","slug":"Javascript-Pattern","permalink":"https://jumpegg.github.io/categories/Javascript-Pattern/"}],"tags":[{"name":"pattern","slug":"pattern","permalink":"https://jumpegg.github.io/tags/pattern/"}]},{"title":"CH 4 트랜잭션(4.4, 4.5)","slug":"mysql-transection3","date":"2017-07-15T01:29:33.000Z","updated":"2017-07-15T04:25:45.876Z","comments":true,"path":"2017/07/15/mysql-transection3/","link":"","permalink":"https://jumpegg.github.io/2017/07/15/mysql-transection3/","excerpt":"","text":"4.4 InnoDB 스토리지 엔진의 잠금InnoDb 스토리지 엔진은 MYSQL에서 제공하는 잠금과는 별개로 스토리지 엔진 내부에서 레코드 기반의 잠금 방식을 탑재하고 있다. InnoDB는 레코드 기반의 잠금 방식 때문에 MyISAM보다는 훨씬 뛰어난 동시성 처리를 제공할 수 있다. 4.4.1 InnoDB의 잠금 방식 비관적 잠금현재 트랜잭션에서 변경하고자 하는 레코드에 대해 잠금을 획득하고 변경 작업을 처리하는 방식 낙관적 잠금 낙관적 잠금에서는 기본적으로 각 트랜잭션이 같은 레코드를 변경할 가능성은 상당히 희박할 것이라고 가정한다. 그래서 우선 변경 작업을 수행하고 마지막에 잠금 충돌이 있었는지 확인해 문제가 있었다면 ROLLBACK처리 하는 방식을 의미한다. 4.4.2 InnoDB의 잠금의 종류 레코드 락(Record lock, Record only lock) 레코드 자체만을 잠그는 것을 레코드 락 이라고 하며, 다른 상용 DBMS의 레코드 락과 동일한 역할을 한다. 한가지 중요한 차이는 InnoDB 스토리지 엔진은 레코드 자체가 아니라 인덱스의 레코드를 잠근다는 점이다. 만약 인덱스가 하나도 없는 테이블이라 하더라도 내부적으로 자동 생성된 클러스터 인덱스를 이용해 잠금을 설정한다. 갭 락(Gap lock) 다른 DBMS와의 또 다른 차이는 바로 갭 락이다. 갭 락은 레코드 그 자체가 아니라 레코드와 바로 인접한 레코드 사이의 간격만을 잠그는 것을 의미한다. 갭 락의 역할은 레코드와 레코드 사이에 새로운 레코드가 생성되는 것을 제어하는 것이다. 넥스트 키 락(Next key lock) 레코드 락과 갭 락을 합쳐 놓은 형태의 잠금을 넥스트 키 락이라고 한다. 자동 증가 락(Auto increment lock) Auto_increment 칼럼이 사용된 테이블에 동시에 여러 레코드가 insert 되는 경우, 저장되는 각 레고드는 중복되지 않고 저장된 순서대로 증가한 일련번호 값을 가져야 한다. InnoDB 스토리지 엔진에서는 이를 위해 내부적으로 Auto_increment 락이라고 하는 테이블의 수준의 잠금을 사용한다. 4.4.3 인덱스와 잠금InnoDB의 잠금과 인덱스는 상당히 중요한 연관 관계가 있다. 레코드 락은 레코드의 인덱스를 잠그는 방식으로 처리된다. 즉, 변경해야 할 레코드를 찾기 위해 검색한 인덱스의 레코드를 모두 잠가야 한다. 하나의 테이블에 update 문장이 실행되면 Mysql의 InnoDB는 인덱스로 사용된 컬럼의 값과 동일한 레코드 들에 락을 건다. 만약 인덱스가 없다면 해당 테이블의 레코드에 모두 락을 건다. 4.4.4 트랜잭션 격리 수준과 잠금이러한 불필요한 레코드의 잠금 현상은 InnoDB의 넥스트 키 락 때문에 발생하는 것이다. 하지만 InnoDB에서 넥스트 키 락을 필요하게 만드는 주 원인은 바로 복제를 위한 바이너리 로그 때문이다. 레코드 기반의 바이너리 로그를 사용하거나 바이너리 로그를 사용하지 않는 경우에는 InnoDB의 갭 락이나 넥스트 키 락의 사용을 대폭 줄일 수 있다. Mysql 5.0innodb_locks_unsafe_for_binlog = 1트랜잭션 격리수준을 READ-COMMIT 로 설정 Mysql 5.1 이상 바이너리 로그를 비활성화 레코드 기반의 바이너리 로그 사용 : innodb_locks_unsafe_for_binlog = 1 4.4.5 레코드 수준의 잠금 확인 및 해제InnoDB 스토리지 엔진을 사용하는 테이블의 레코드 수준 잠금은 테이블 수준의 잠금보다는 복잡하다.(복잡해서 요약이 안됨) 4.5 Mysql의 격리 수준트랜잭션의 격리 수준이란 동시에 여러 트랜잭션이 처리될 때, 득정 트랜잭션이 다른 트랜잭션에서 변경하거나 조회하는 데이터를 볼 수 있도록 허용할지 말지를 결정하는 것이다. 격리 수준은 크게 READ UNCOMMITED, READ COMMITED, REPEATABLE READ, SERIALIZABLE 의 4가지로 나뉜다. 데이터베이스의 격리수준을 이야기 하면 항상 언급되는 것은 부정합이다. 3가지 부정합 문제가 있으며 각각의 격리수준에 따른 부정합 문제는 다음과 같다. 격리수준 DIRTY READ NON-REPEATABLE READ PHANTOM READ READ UNCOMMITTED 발생 발생 발생 READ COMMITTED 발생하지 않음 발생 발생 REPEATABLE READ 발생하지 않음 발생하지 않음 발생(InnoDB는 발생하지 않음) SERIALIZABLE 발생하지 않음 발생하지 않음 발생하지 않음 4.5.1 READ UNCOMMITTEDREAD UNCOMMITTED 격리 수준에서는 각 트랜잭션에서의 변경 내용이 COMMIT이나 ROLLBACK 여부에 상관 없이 다른 트랜잭션에서 보여진다. 이때 다른 트랜잭션에는 변경된 레코드가 반영되지 않는 현상을 Dirty read 라고 한다. Dirty read는 사용자와 개발자를 혼란스럽게 한다. 4.5.2 READ COMMITTEDREAD COMMITTED는 오라클 DBMS에서 기본적으로 사용되는 격리 수준이며, 온라인 서비스에서 가장 많이 선택되는 격리 수준이다. Dirty read 같은 현상은 발생하지 않는다. 어떤 트랜잭션에서 데이터를 변경했더라도 Commit이 완료된 데이터만 다른 트랜잭션에서 조회할 수 있기 때문이다. READ COMMITTED는 Non-repeatable read 부정합의 문제가 있다. 데이터 변경 후 커밋 이전에 조회문을 날렸을 때와 커밋 이후에 조회문을 날렸을 때 가져오는 데이터가 다른 경우, 하나의 트랜잭션에서 똑같은 select 쿼리를 실행했을 때 항상 같은 결과를 가져와야 하는데 위의 경우는 다른 결과를 가져오게 된다. 이러한 부정합 현상은 일반적인 웹에서는 문제는 없지만 하나의 트랜잭션에서 데이터를 여러번 읽고 변경하는 작업이 금전적인 처리와 연결되면 문제가 될 수 있다. 4.5.3 REPEATABLE READREPEATABLE READ는 Mysql의 InnoDB 스토리지 엔진에서 기본적으로 사용되는 격리 수준이다. 바이너리 로그를 가진 Mysql의 장비에서는 최소 Repeatable read 격리 수준 이상을 사용해야 한다. InnoDB에서는 MVCC를 위해 Undo 영역에 백업된 이전 데이터를 이용해 동일 트랜잭션 내에서는 동일한 결과를 보여줄 수 있도록 보장한다. 4.5.4. SERIALIZABLE가장 단순한 격리 수준이지만 가장 엄격한 격리 수준이다. 또한 그만큼 동시 처리 성능도 다른 트랜잭션 격리 수준보다 떨어진다. 트랜잭션의 격리수준이 SERIALIZABLE 로 설정되면 일기 작업도 공유 잠금을 획득해야만 하며, 동시에 다른 트랜잭션은 그러한 레코드를 변경하지 못하게 된다. 즉, 한 트랜잭션에서 읽고 쓰는 레코드를 다른 트랜잭션에서는 절대 접근할 수 없는 것이다.","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"transection","slug":"transection","permalink":"https://jumpegg.github.io/tags/transection/"}]},{"title":"ionic root nav 문제해결","slug":"ionic-problem-01","date":"2017-07-13T09:09:16.000Z","updated":"2017-07-13T09:39:25.897Z","comments":true,"path":"2017/07/13/ionic-problem-01/","link":"","permalink":"https://jumpegg.github.io/2017/07/13/ionic-problem-01/","excerpt":"","text":"Ionic root 문제ionic을 사용하다 보면 페이지 컨트롤을 위해서 자연적으로 NavController를 사용하게 되는데, 정확히 파악하지 않은 상태에서 NavCtrl을 사용하다 보니 내가 생각했던 구조대로 앱이 만들어지지 않고 있다는 것을 깨닫게 되었다. 문제점우선 내가 의도한 구조는 이렇다123456789101112131415app&lt;Nav&gt;&#123; LoginPage, UserPage&lt;Nav&gt;:[ page1, page2, page3, ..... ], StudyPage&lt;Nav&gt;:[ page1, page2, page3, ..... ],&#125; 하지만 내가 만든 구조는 이렇게 되어있었다.123456789101112131415app&lt;Nav&gt;&#123; LoginPage, UserPage&lt;Nav&gt;:[ page1, page2, page3, ..... StudyPage&lt;Nav&gt;:[ page1, page2, page3, ..... ] ]&#125; 상황이 심각하다. 문제인식구조가 잘못되고 있다는것을 인식한 것은 UserPage에서 생성한 css 가 StudyPage에 영향을 미치고 있는걸 보고 알게 되었다. 기본적으로 ionic은 각 페이지 별로 css 정의를 할 수 있고, 자식 컴포넌트가 아니면 css간 영향이 없다. 원인공식 홈페이지나 구글링을 통해 얻을 수 있는 Tutorial 을 따라하다 보면 navCtrl.push(), navCtrl.pop(), navCtrl.setRoot() 에 관한 설명은 잘 되어있으나 그 이상은 설명되어 있지 않으며 여기서 필자의 경우엔 setRoot() 의 작동방식을 착각한 것이 원인이었다. 해결여기 저기에서 사용한 setRoot()는 해당 컴포넌트에 ion-nav 를 사용하지 않으면 부모 컴포넌트의 ion-nav 를 바꿔주었지만, 컴포넌트에 ion-nav 가 있는 경우 해당 컴포넌트의 ion-nav를 바꿔준다. 그래서 최상단의 navCtrl을 가져오기 위해선 App을 가져와야 한다. 12345678910111213141516171819import &#123; App, NavCtroller, NavParams&#125; from 'ionic-angular';....@Component(&#123; selector: 'your-selector', templateUrl: 'your-template.html'&#125;)export class YourPage&#123; constructor( public navCtrl: NavController, public navParams: NavParams, public appCtrl: App )&#123;&#125; ........... moveToPage()&#123; // getRootNav()는 최상단의 nav를 가져온다. this.appCtrl.getRootNav().setRoot(NextPage); &#125;&#125; 출처stack overflow","categories":[{"name":"문제해결","slug":"문제해결","permalink":"https://jumpegg.github.io/categories/문제해결/"}],"tags":[{"name":"ionic-root","slug":"ionic-root","permalink":"https://jumpegg.github.io/tags/ionic-root/"}]},{"title":"ionic-menu","slug":"ionic-menu","date":"2017-07-12T08:59:02.000Z","updated":"2017-07-20T05:46:59.497Z","comments":true,"path":"2017/07/12/ionic-menu/","link":"","permalink":"https://jumpegg.github.io/2017/07/12/ionic-menu/","excerpt":"","text":"IONIC Menu 사용법ionic menu 사용ion-menu 는 사이드 메뉴를 만드는데 사용된다.12345678910&lt;!-- 템플릿 사이드 코드 --&gt;&lt;ion-menu [content]=\"mycontent\"&gt; &lt;ion-content&gt; &lt;ion-list&gt; &lt;p&gt;some menu content, could be list items&lt;/p&gt; &lt;/ion-list&gt; &lt;/ion-content&gt;&lt;/ion-menu&gt;&lt;ion-nav #mycontent [root]=\"rootPage\"&gt;&lt;/ion-nav&gt; 사이드 메뉴를 열 수 있는 버튼 생성 1234&lt;button menuToggle&gt; &lt;ion-icon name=\"menu\"&gt;&lt;/ion-icon&gt;&lt;/button&gt; 1234567891011121314151617181920212223import &#123; Component &#125; from '@angular/core';import &#123; MenuController &#125; from 'ionic-angular';@Component(&#123;...&#125;)export class MyPage &#123; constructor(public menuCtrl: MenuController) &#123; &#125; openMenu() &#123; this.menuCtrl.open(); &#125; closeMenu() &#123; this.menuCtrl.close(); &#125; toggleMenu() &#123; this.menuCtrl.toggle(); &#125;&#125;","categories":[{"name":"ionic2","slug":"ionic2","permalink":"https://jumpegg.github.io/categories/ionic2/"}],"tags":[{"name":"ionic2-menu","slug":"ionic2-menu","permalink":"https://jumpegg.github.io/tags/ionic2-menu/"}]},{"title":"CH 4 트랜잭션(4.2, 4.3)","slug":"mysql-transection2","date":"2017-07-12T05:45:19.000Z","updated":"2017-07-15T01:30:21.615Z","comments":true,"path":"2017/07/12/mysql-transection2/","link":"","permalink":"https://jumpegg.github.io/2017/07/12/mysql-transection2/","excerpt":"","text":"4.2 Mysql 엔진의 잠금Mysql 에서 사용되는 잠금은 크게 스토리지 엔진 레벨과 Mysql 엔진 레벨로 나눠볼 수 있다. Mysql 엔진은 Mysql 서버에서 스토리지 엔진을 제외한 나머지 부분으로 이해하면 되는데, Mysql 엔진 레벨의 잠금은 모든 스토리지 엔진에 영향을 미치게 되지만 스토리지 엔진 레벨의 잠금은 스토리지 엔진 간 상호 영향을 미치지 않는다. 4.2.1 글로벌 락 (Global Lock)글로벌락은 “flush tables with read lock” 명령으로만 획득할 수 있으며, Mysql에서 제공하는 잠금 가운데 가장 범위가 크다. 글로벌 락이 영향을 미치는 범위는 Mysql 서버 전체이며, 작업 대상 테이블이나 데이터베이스가 다르다 하더라도 동일하게 영향을 미친다. 4.2.2 테이블 락 (Table Lock)개별 테이블 단위로 설정되는 잠금이며, 명시적 또는 묵시적으로 특정 테이블의 락을 획득할 수 있다. 명시적으로는 “lock tables table_name [READ | WRITE]” 명령으로 특정 테이블의 락을 획득할 수 있다. 테이블 락은 MyISAM뿐 아니라 InnoDB 스토리지 엔진을 사용하는 테이블도 동일하게 설정할 수 있다. 명시적으로 획득한 잠금은 “Unlock Tables” 명령으로 잠금을 반납(해제) 할 수 있다. 4.2.3 유저 락 (User Lock)Get_lock() 함수를 이용해 임의로 잠금을 설정할 수 있다. 이 잠금의 특징은 대상이 테이블이나 레코드 또는 Auto_increment 와 같은 데이터베이스 객체가 아니라는 것이다. 유저락은 단순히 사용자가 지정한 문자열에 대해 획득하고 반납하는 잠금이다. 여러 클라이언트가 상호 동기화를 처리해야 할때 데이터베이스의 유저 락을 이용하면 쉽게 해결할 수 있다. 또한 유저락은 많은 레코드를 한번에 변경해야 하는 트랜잭션의 경우에 유용하게 사용할 수 있다. 배치 프로그램처럼 한번에 많은 레코드를 변경하는 경우 데드락의 원인이 되곤 한다. 이때 동일한 데이터를 변경하는 프로그램끼리 분류해서 유저 락을 걸고 쿼리를 실행하면 아주 간단히 해결할 수 있다. 4.2.4. 네임 락 (Name Lock)데이터베이스 객체의 이름을 변경하는 경우 획득하는 잠금이다. 네임 락은 명시적으로 획득하거나 해제할 수 있는 것이 아니고 “Rename table tab_a To tab_b” 같은 테이블의 이름을 변경하는 경우 자동으로 획득하는 잠금이다. 4.3 MyISAM 과 MEMORY 스토리지 엔진의 잠금MyISAM 이나 MEMORY 스토리지 엔진은 자체적인 잠금을 가지지 않고 MYSQL 엔진에서 제공하는 테이블 락을 그대로 사용한다. 그리고 MyISAM 이나 MEMORY 스토리지 엔진에서는 쿼리 단위로 필요한 잠금을 한꺼번에 요청해서 획득하기 때문에 데드락이 발생할 수 없다. 4.3.1 잠금 획득 읽기 잠금테이블에 쓰기 잠금이 걸려 있지 않으면 바로 일기 잠금을 획득하고 읽기 작업을 시작할 수 있다. 쓰기 잠금테이블에 아무런 잠금이 걸려있지 않아야만 쓰기 잠금을 획득할 수 있고, 그렇지 않다면 다른 잠금이 해제될 때까지 대기해야 한다. 4.3.2 잠금 튜닝테이블 락에 대한 작업 상황은 MYSQL 의 상태 변수를 통해 확인할 수 있다. 12345678mysql&gt; show status like 'Table%';+-----------------------+---------+| Variable_name | Value |+-----------------------+---------+| Table_locks_immediate | 1551552 || Table_locks_waited | 15324 |+-----------------------+---------+ Table_locks_immediate 는 다른 잠금이 풀리기를 기다리지 않고 바로 잠금을 획득한 횟수이며, Table_locks_waited 는 다른 잠금이 이미 해당 테이블을 사용하고 있어서 기다려야 했던 횟수를 누적해서 저장하고 있다. 잠금 대기 쿼리 비율 = Table_locks_waited / (Table_locks_immediate + Table_locks_waited) * 100; 위의 수치들을 대입해보면 약 1.31% 의 수치를 얻을 수 있으며, 이는 100개의 쿼리중 1개는 잠금 대기를 겪고 있다는 것을 알 수 있다. 4.3.3 테이블 수준의 잠금 확인 및 해제MYISAM 이나 MEMORY 등과 같은 스토리지 엔진을 사용하는 테이블은 모두 테이블 단위의 잠금이므로 테이블을 해제하지 않으면 다른 클라이언트에서 그 테이블을 사용하는 것이 불가능하다. MYSQL 에서 현재 어떤 테이블이 잠겨있는지 확인하는 방법을 알아보자 MYSQL에서 테이블의 잠금을 획득하는 방법은 LOCK TABLES 명령을 이용해 명시적으로 획득하는 방법과, 쿼리문을 통한 묵시적 잠금획득 방법이 있다. 명시적인 방법은 UNLOCK TABLES 명령으로 해제하기 전에는 자동으로 해제되지 않는다. 아무런 옵션 없이 SHOW OPEN TABLES 명령을 바로 실행하면 MYSQL 서버의 모든 테이블에 대해 잠금 여부를 보여주고, FROM DB명 을 추가하면 해당 DB에 생성된 테이블에 대해 잠금 상태를 표시한다. SHOW OPEN TABLES 명령의 결과로 출력되는 in_use 값은 해당 테이블을 잠그고 있는 클라이언트 수와 테이블의 잠금을 기다리는 클라이언트의 수까지 더해서 출력된다. 그리고 “Name_locked” 는 테이블 이름에 대한 네임 락이 걸려 있는지를 표시한다. 어떤 클라이언트의 커넥션이 잠금을 기다리고 있는지 보려면 SHOW PROCESSLIST 명령을 사용해야 한다.","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"transection","slug":"transection","permalink":"https://jumpegg.github.io/tags/transection/"}]},{"title":"CH 4 트랜젝션(4.1)","slug":"mysql-transection1","date":"2017-07-12T03:41:19.000Z","updated":"2017-07-12T05:33:51.471Z","comments":true,"path":"2017/07/12/mysql-transection1/","link":"","permalink":"https://jumpegg.github.io/2017/07/12/mysql-transection1/","excerpt":"","text":"Mysql 에서 동시성에 영향을 주는 잠금(lock) 과 트랜잭션, 그리고 트랜잭션의 격리수준(isolation level) 을 살펴보겠다. 잠금(lock) 과 트랜잭션은 서로 비슷한 개념 같지만 사실 잠금은 동시성을 제어하기 위한 기능이고 트랜잭션은 데이터의 정합성을 보장하기 위한 기능이다. 4.1 트랜잭션4.1.1 Mysql에서의 트랜잭션트랜잭션은 하나의 논리적인 작업 셋에 하나의 쿼리가 있든 두개 이상의 쿼리가 있든 관계없이 논리적인 작업 셋 자체가 100% 적용되거나(commit을 실행했을 때) 또는 아무것도 적용되지 않아야 (RollBack 또는 Transection Rollback 시키는 오류가 발생했을 때) 함을 보장해 주는 것이다. 12345mysql&gt; create table tab_myisam (fdpk int not null, primary key(fdpk)) engine=MyISAM;mysql&gt; insert into tab_myisam (fdpk) values (3);mysql&gt; create table tab_innodb (fdpk int not null, primary key (fdpk)) engine=innoDB;mysql&gt; insert into tab_innodb (fdpk) values (3); 위와같이 테스트 테이블을 생성 후 auto-commit 모드에서 다음 쿼리 문장을 실행해 보자 12mysql&gt; insert into tab_myisam (fdpk) values (1), (2), (3);mysql&gt; insert into tab_innodb (fdpk) values (1), (2), (3); 두 개의 스토리지 엔진에서 결과가 어떻게 다를까? 위 쿼리 문장의 테스트 결과는 다음과 같다. 123456789101112131415161718192021mysql&gt; Insert into tab_myisam (fdpk) values (1), (2), (3);error 1062 ......mysql&gt; insert into tab_innodb (fdpk) values (1), (2), (3);error 1062 ...mysql&gt; select * from tab_myisam;+-------+| fdpk |+-------+| 1 || 2 || 3 |+-------+mysql&gt; select * from tab_innodb;+-------+| fdpk |+-------+| 3 |+-------+ MyISAM의 경우 오류가 발생했음에도 1,2 가 들어가 있다. MyISAM 테이블에 insert 문장이 실행되면서 차례대로 1,2를 저장하고 그 다음 3을 저장하려는 순간 중복키 오류가 발생한 것이다. InnoDB는 쿼리 중 일부라도 오류가 발생하면 전체를 원 상태로 만들어 둔다는 트랜잭션의 원칙대로 insert 쿼리 문장을 실행하기 전 상태로 그대로 복구했다. MyISAM에서 발생하는 이런 현상을 부분 업데이트(partial update)라고 하며, 이것은 테이블 데이터의 정합성을 맞추는데 상당한 어려움을 유발시킨다. 4.1.2 주의사항트랜잭션 또한 DBMS의 커넥션과 동일하게 꼭 필요한 최소의 코드에만 적용하는 것이 좋다. 이는 프로그램 코드에서 트랜잭션의 범위를 최소화 하라는 의미다. 설명을 위해 간단한 예를 들어보자 처리시작 =&gt; 데이터베이스 커넥션 생성 =&gt; 트랜잭션 시작 사용자의 로그인 여부 확인 사용자의 글쓰기 내용의 오류 여부 확인 첨부로 업로드된 파일 확인 및 저장 사용자의 입력 내용을 DBMS에 저장 첨부 파일 정보를 DBMS에 저장 저장된 내용 또는 기타 정보를 DBMS에서 조회 게시물 등록에 대한 알림 메일 발송 알림 메일 발송 이력을 DBMS에 저장 &lt;= 트랜잭션 종료 (commit) &lt;= 데이터베이스 커넥션 반납 처리 완료 위 처리절차 중에 DBMS의 트랜잭션 처리에 좋지 않은 영향을 끼치는 부분을 나눠서 살펴보자 커넥션 생성을 1과 2번 사이에 구현했는데 DB의 사용은 5~9 사이에 이루어진다. DB의 커넥션은 제한적이라 커넥션 유지 부분을 짧게 작성 할 수록 좋다. 8번의 메일전송이나 FTP 파일 전송작업 또는 네트워크를 통해 원격 서버와 통신하는 등과 같은 작업은 어떻게든 트랜잭션 내에서 제거하는 것이 좋다. 프로그램 실행 중에 메일서버와 통신할 수 없는 상황이 발생한다면 웹 서버뿐 아니라 DBMS 서버까지 위험해지는 상황이 발생 할 것이다. 위의 과정 중 5,6번 작업은 반드시 하나의 트랜잭션으로 묶어야 하며, 7번작업은 저장된 데이터의 단순 확인작업이므로 트랜잭션에 포함시킬 필요 없다. 9번작업은 이전 5,6 번 작업과 성격이 다르기 때문에 같은 트랜잭션으로 묶을 필요가 없다. 이러한 내용을 적용시켜 재설계 해보자 처리 시작 사용자의 로그인 여부 확인 사용자의 클쓰기 내용의 오류 발생 여부 확인 첨부로 업로드된 파일 확인 및 저장 =&gt; 데이터베이스 커넥션 생성 =&gt; 트랜잭션 시작 사용자의 입력 내용을 DBMS에 저장 첨부 파일 정보를 DBMS에 저장 &lt;= 트랜잭션 종료 저장된 내용 또는 기타 정보를 DBMS에서 조회 게시물 등록에 대한 알림 메일 발송 =&gt; 트랜잭션 시작 알림 메일 발송 이력을 DBMS에 저장 &lt;= 트랜잭션 종료 &lt;= 데이터베이스 커넥션 종료 처리 완료","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"transection","slug":"transection","permalink":"https://jumpegg.github.io/tags/transection/"}]},{"title":"Ionic Guard 구현","slug":"Ionic-nav-guard","date":"2017-07-09T05:23:41.000Z","updated":"2017-07-12T08:59:34.950Z","comments":true,"path":"2017/07/09/Ionic-nav-guard/","link":"","permalink":"https://jumpegg.github.io/2017/07/09/Ionic-nav-guard/","excerpt":"","text":"Lifecyle 을 이용한 구현Angular 에서는 route 부분에서 guard를 구현해 해당 페이지에 접근가능/불가 를 제어한다. ionic에서는 해당 기능을 lifecycle을 통해 제공하고 있다. ionViewCanEnter / ionViewCanLeaveNavController에 ionViewCanEnter 와 ionViewCanLeave 는 페이지의 접근 관련제어를 담당하고 있다. ionViewCanLeave 예제 1234567891011121314151617export class MyClass&#123; constructor( public navCtrl: NavController )&#123;&#125; pushPage()&#123; this.navCtrl.push(DetailPage); &#125; ionViewCanLeave(): boolean&#123; if(isValid(CanILeave))&#123; return true; &#125;else&#123; return false; &#125; &#125;&#125; ionViewCanEnter 예제 1234567891011121314151617181920212223export class MyClass&#123; constructor( public navCtrl: NavController )&#123;&#125; pushPage()&#123; this.navCtrl.push(DetailPage); &#125;&#125;export class DetailPage()&#123; constructor( public navCtrl: NavController )&#123;&#125; ionViewCanEnter(): boolean&#123; if(isValid(CanIEnter))&#123; return true; &#125;else&#123; return false; &#125; &#125;&#125; ionViewCanEnter, ionViewCanLeave 둘 다 boolean/Promise 의 리턴 형태를 가지고 있으므로 형태에 맞게 사용하면 되겟다","categories":[{"name":"ionic2","slug":"ionic2","permalink":"https://jumpegg.github.io/categories/ionic2/"}],"tags":[{"name":"ionic2-nav","slug":"ionic2-nav","permalink":"https://jumpegg.github.io/tags/ionic2-nav/"}]},{"title":"3. Mysql 아키텍처(3.7, 3.8)","slug":"Mysql-architecture4","date":"2017-07-08T14:41:26.000Z","updated":"2017-07-12T05:45:41.224Z","comments":true,"path":"2017/07/08/Mysql-architecture4/","link":"","permalink":"https://jumpegg.github.io/2017/07/08/Mysql-architecture4/","excerpt":"","text":"3.7 전문 검색 엔진(Fulltext search engine)최근 인터넷 서비스는 대부분 본문 검색이 기본적으로 포함되는 경우가 많은데, 이러한 요건은 전문 검색 엔진 없이는 구현하기가 쉽지 않다. 여기서는 한글을 지원하고, 어느정도 수준의 성능을 보장하고 있는 트리톤과 스핑크스라는 검색엔진을 간단하게 살펴본다. 3.7.1 트리톤 전문 검색 엔진트리톤을 사용하려면 먼저 Mysql의 소스코드를 패치한 후, 다시 빌드해야 하며 그 이후에 InnoDB같이 하나의 스토리지 엔진으로 사용할 수 있다. 한, 중, 일 아시아권 언어 지원이 강점이며 또한 세나(Senna) 라이브러리를 이용한 빠른 인덱싱과 검색을 제공한다. 또한 Mysql 서버의 전문 검색엔진과 달리 N-그램 방식의 인덱싱도 사용할 수 있다는 것이 가장 큰 장점이다. 3.7.2 mGroonga 전문 검색 엔진(플러그인)트리톤은 Mysql 5.0.87 버전에서만 사용할 수 있다. 트리톤을 5.1, 5.5 버전에서 사용해야 한다면 트리톤의 후속작인 Groonga 라는 전문 검색 엔진을 사용해야 한다. 하지만 Groonga는 Mysql과 전혀 연관없이 독립적으로 기동하는 소프트웨어라서 Mysql에 익숙한 사용자를 위해 mGroonga 라는 플러그인을 함께 제공한다. 3.7.3 스핑크스 전문 검색 엔진스핑크스는 Mysql 서버와는 전혀 연관이 없이 자체적인 저장 공간을 가지고 별도의 프로세스로 작동하며, Mysql 서버를 통해 접근할 수 있는 인터페이스만 제공하는 형태의 스토리지 엔진이다. N-그램방식의 인덱싱과 UTF-8 언어를 지원하는것과 분산처리 기능이 상당히 뛰어나다는 것이 장점이다. 3.8 Mysql 로그 파일3.8.1 에러 로그 파일Mysql이 실행되는 도중에 발생하는 에러나 경고 메세지가 출력되는 로그 파일이다. 에러 로그 파일의 위치는 configure 파일에 “log_error” 라는 이름의 파라미터에 정의된 경로에 있는 파일이거나, 별도로 지정되지 않은 경우에는 데이터 디렉터리에 “.err” 확장자가 붙은 파일이다. 여러가지 메시지가 다양하게 출력되지만 다음에 소개되는 메시지를 가장 자주 보게 될 것이다. Mysql 이 시작하는 과정과 관련된 정보성 및 에러 메시지 마지막으로 종료할 때 비정상적으로 종료된 경우 나타나는 InnoDB의 트랜잭션 복구 메시지 쿼리 처리 도중에 발생하는 문제에 대한 에러 메시지 비정상적으로 종료된 커넥션 메시지 InnoDB의 모니터링 명령이나 상태 조회 명령의 결과 메시지 Mysql 종료 메시지 3.8.2 제너럴 쿼리 로그 파일쿼리 로그파일은 configure 파일의 “general-log” 라는 이름의 파라메터에 정의된 경로에 있는 파일이고 Mysql 5.1.12 이상의 버전에서는 “general_log_file” 이라는 이름의 파라메터에 정의된 경로에 있는 파일이다. 3.8.3 슬로우 쿼리 로그Mysql 서버의 쿼리 튜닝은 크게 서비스가 적용되기 전에 전체적으로 튜닝하는 경우와 서비스 운영중에 Mysql 서버의 전체적인 성능 저하를 검사하거나 또는 정기적인 점검을 위한 튜닝으로 나눌 수 있다. 전자의 경우에는 검토해야 할 대상 쿼리가 전부라서 모두 튜닝하면 되지만, 후자의 경우에는 어떤 쿼리가 문제의 쿼리인지 판단하기가 상당히 어렵다. 이런 경우에 서비스에서 사용되고 있는 쿼리 중에서 어떤 쿼리가 문제인지를 판단하는데 슬로우 쿼리 로그가 상당히 많은 도움이 된다. 슬로우 쿼리 로그 파일에는 configure 에서 정의한 시간(long_query_time) 이상의 시간이 소요된 쿼리가 모두 기록된다. 실제 소요된 시간을 기준으로 기록 여부를 판단하기 때문에 정상적으로 실행된 쿼리만 기록된다.","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/tags/Mysql/"}]},{"title":"3. Mysql 아키텍처(3.4, 3.5, 3.6)","slug":"Mysql-architecture3","date":"2017-07-08T13:22:33.000Z","updated":"2017-07-12T05:45:37.028Z","comments":true,"path":"2017/07/08/Mysql-architecture3/","link":"","permalink":"https://jumpegg.github.io/2017/07/08/Mysql-architecture3/","excerpt":"","text":"3.4 Memory 스토리지 엔진 아키텍처Memory 스토리지 엔진은 Heap 스토리지 엔진 이라고도 하는데, 이름 그대로 데이터를 메모리에 저장하는 것이 특징이다. 데이터의 크기가 작고 아주 빠른 처리가 필요한 경우 적합한 엔진이다. 3.4.1 주의사항테이블의 최대 크기다른 스토리지 엔진을 이용한 테이블과는 달리 Memory 스토리지 엔진을 사용하는 테이블은 저장할 수 있는 데이터의 최대 용량이 정해져 있다. 최대 데이터의 크기는 max_heap_table_size 파라미터로 정의한다 고정 길이 칼럼만 지원Memory 테이블의 모든 칼럼은 항상 고정 길이로만 생성된다. 즉 varchar(100)와 같은 타입의 칼럼을 만들어도 char(100)과 동일하게 공간이 할당된다는 의미이다. 따라서 불필요하게 너무 큰 데이터 타입을 사용하지 않는 것이 좋다. Blob 이나 Text와 같은 LOB(Large Object) 타입은 지원하지 않음Memory 테이블은 기본적으로 해시 인덱스 사용InnoDB나 MyISAM 테이블을 생성할 때 별다른 내용을 명시하지 않으면 기본적으로 B-Tree 인덱스가 생성되지만 Memory 스토리지 엔진을 사용하면 해시 인덱스를 생성한다. 3.4.2 용도Memory 스토리지는 사실 Mysql 엔진이 쿼리를 처리하는 과정에서 임시로 생성되는 임시 테이블 용도로 자주 사용된다. 3.5 NDB 클러스터 스토리지 엔진NDB 클러스터는 “Network DataBase” 의 줄임말로 일반적으로 NDB 라 불리운다. NDB는 데이터의 분산이나 그로인한 성능 향상 보다는 가용성에 집중된 스토리지 엔진이다. 3.5.1 NDB 클러스터의 특성무공유 클러스터링NDB는 데이터를 저장하는 스토리지가 분산되어 관리되기 때문에 하나의 데이터 저장소가 작동을 멈추더라도 서비스에 영향을 미치지 않는다. 메모리 기반의 스토리지 엔진NDB는 클러스터 노드 간의 빠른 데이터 동기화를 위해 메모리를 사용한다. NDB 클러스터는 데이터 스토리지까지 분산하기 때문에 각 노드의 물리적 메모리를 모두 합친 것이 실제 저장 가능한 최대 용량이 된다. 자동화된 Fail-overNDB는 모든 구성 노드가 서로의 상태를 계속 체크하고 있기 때문에 특정 노드에 문제가 발생해도 다른 사용 가능한 노드가 그 역할을 이어받는 형태로 페일 오버가 가능하다. 분산된 데이터 저장소간의 동기 방식(Sync) 복제NDB에서 데이터 저장소는 분산되어 관리되는데, 각 데이터 저장소는 전체 데이터를 N등분해서 자신이 전담하는 파티션과 백업으로 보조 파티션을 구성한다. 각 데이터 저장소는 분산된 서로의 데이터를 동기화 해야 하는데 NDB는 비동기 방식이 아닌 동기 방식으로 서로의 데이터를 전달한다. 온라인 스키마 변경NDB는 테이블에 칼럼이나 인덱스를 추가하면서 동시에 Insert 나 Update와 같은 DML 쿼리를 처리할 수 있다. 이를 온라인 스키마 변경이라 하는데 사용하는 방법은 Alter table 이나 Create index 명령에 Online 키워드를 사용하면 된다. Online 키워드를 사용하지 않은 스키마 변경 쿼리(DDL)은 클러스터가 온라인 처리 유무를 판단하고 가능한 경우 온라인 방식으로 처리한다. NoSql네트워크 DBNDB는 내부적으로 데이터를 저장하고 읽기 위해 네트워크를 기반으로 작동한다. 이는 하나의 서버에서 모든 처리가 일어나는 다른 스토리지 엔진과는 상당히 다른 개념이다 3.5.2 NDB 클러스터의 아키텍처NDB 클러스터 노드의 종류 관리노드 관리노드는 실제 NDB가 정상 상태에서 서비스되는 도중에는 거의 하는 일이 없다. 관리노드는 NDB 클러스터의 전체적인 구조에 대한 정보를 다른 노드에게 전파하거나 각 노드의 장애 상황을 전파하는 역할을 담당한다. 데이터 노드 데이터 노드는 클러스터에 대한 전반적인 작업을 수행하는 노드다. 대표적으로는 데이터를 저장하는 스토리지를 관리하고 SQL 노드에서 오는 데이터 조작 요청을 모두 처리한다. 또한 SQL 노드가 아닌 API 노드의 요청도 처리한다. 기본적으로 데이터에 관련된 모든 요청을 데이터 노드가 처리한다고 이해하면 된다. SQL 노드 NDB에 접속해 데이ㅓ를 읽고 쓰는 방법은 Mysql 서버를 통해 Sql 문법으로 처리할 수도 있지만 자바나 C 같은 프로그래밍 언어를 이용해 클러스터의 데이터를 조작할 수도 있다. 후자의 방법은 NDB API를 이용하는 방법으로 API 노드라고 표현한다. 반면 SQL서버를 이용해 NDB에 접속하는 경우를 SQL 노드라고 한다. 데이터 노드 간의 파티션 관리NDB 클러스터는 데이터 노드가 손상되어도 서비스가 가능하도록 클러스터 데이터를 파티션해서 각 파티션을 최소 2개 이상의 데이터 노드에 복제해둔다. 또한 원활한 관리를 위해 데이터 노드를 노드 그룹으로 나누는데, 노드 그룹에는 반드시 1개 이상의 데이터 노드가 존재해야 하며, 노드 그룹에 속한 데이터 노드는 항상 동일한 데이터 파티션을 가진다. 3.5.3 클러스터 간의 복제 구성NDB 클러스터에도 Mysql의 복제를 적용할 수 있는데, 이런 경우는 특별히 클러스터간 복제라고 표현한다. 3.5.6 NDB 클러스터의 용도처음에 NDB는 이동통신 사용자의 로그인 정보를 저장하는데 있었는데, 가용성이 극대화된, 소위 세션 데이터 전용 데이터베이스를 만드는 것이 목적이었다. 지금도 세션 전용 데이터베이스로 많이 사용되고 있다. 3.6 TOKUDB 스토리지 엔진3.6.1 프랙탈 트리(Fractal Tree) 인덱스 지원B-Tree의 경우 계속되는 Insert, Update, Delete 작업으로 인해 인덱스 페이지 내에 사용되지 못하는 공간이 생기는데 이를 단편화라고 한다. 단편화 현상에 의해 동일한 레코드건수를 조회 하더라도 디스크에서 읽어야 할 인덱스의 숫자가 많아질 수 있고, 버퍼 풀과 같은 캐시영역의 공간도 많이 차지하게 된다. 이러한 현상은 범위 검색과 같은 작업에 비효율성을 발생시킨다. 프랙탈 트리 인덱스는 B-Tree의 단점을 보완한 새로운 형태의 인덱싱 알고리즘이며, 이 알고리즘을 사용한 TokuDB는 프랙탈 트리의 알고리즘 개발자가 설립한 회사에서 출시한 스토리지 엔진이다. 3.6.2 대용량 데이터와 빠른 Insert 처리위와 같은 프랙탈 트리를 사용함으로써 인덱스에 새로운 레코드를 추가하는 작업이 상당히 빨라진다. 3.6.3 트랜잭션 및 잠금 처리3.6.4 그 이외의 특징3.6.5 TokuDB의 주 용도 SNS 기반의 대용량 테이블(동시성을 크게 요하지 않는) 실시간 웹페이지 클릭 분석 웹 서버나 게임 서버의 로그 분석 고성능 웹 크롤링 데이터웨어 하우스","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/tags/Mysql/"}]},{"title":"3. Mysql 아키텍처(3.2, 3.3)","slug":"Mysql-architecture2","date":"2017-07-08T09:02:39.000Z","updated":"2017-07-12T05:45:37.713Z","comments":true,"path":"2017/07/08/Mysql-architecture2/","link":"","permalink":"https://jumpegg.github.io/2017/07/08/Mysql-architecture2/","excerpt":"","text":"3.2 InnoDB 스토리지 엔진 아키텍처3.2.1 InnoDB 스토리지 엔진의 특성PK에 의한 클러스터링InnoDB의 모든 데이터 테이블은 기본적으로 프라이머리 키를 기준으로 클러스터링 되어 저장된다. 즉 PK값의 순서대로 디스크에 저장된다는 의미이며, 이로 인해 PK에 의한 레인지 스캔은 상당히 빨리 처리될 수 있다. 잠금이 필요없는 일관된 읽기InnoDB는 MVCC(Multi Version Concurrency Control)라는 기술을 이용해 락을 걸지 않고 읽기 작업을 수행한다. 외래 키 지원InnoDB에서는 외래키를 지원하지만 실무에서는 여러가지 제약때문에 잘 사용하지 않다. 하지만 데이터베이스의 좋은 가이드 역할로 사용이 가능하다. 자동 데드락 감지InnoDB는 그래프 기반의 데드락 체크 방식을 사용하기 때문에 데드락이 발생함과 동시에 바로 감지되고, 감지된 데드락은 관련 트랜잭션 중에서 rollback 이 가장 용이한 트랜잭션을 자동적으로 강제 종료해 버린다. 자동화된 장애 복구오라클의 아키텍처 적용3.2.2 InnoDB 버퍼 풀InnoDB 스토리지 엔젠에서 가장 핵심적인 부분으로, 디스크의 데이터 파일이나 인덱스 정보를 메모리에 캐시해 두는 공간이다. MyISAM 키 캐시가 인덱스의 캐시만을 주로 처리하는데 비해 InnoDB의 버퍼 풀은 데이터와 인덱스 모두 캐시하고 쓰기 버퍼링의 역할까지 모두 처리하고 있는 것이다. 3.2.3 Undo 로그언두 영역은 update, delete와 같은 문장으로 데이터를 변경했을 때 변경되기 전의 데이터를 보관하는 곳이다. 언두의 데이터는 크게 두가지 용도로 사용되는데, 첫 번째가 트랜잭션의 롤백 대비용, 두 번째는 트랜잭션의 격리 수준을 유지하면서 높은 동시성을 제공하는 데 사용된다. 트랜잭션의 격리 수준이라는 개념이 있는데, 이는 동시에 여러 트랜잭션이 데이터를 변경하거나 조회할 때, 한 트랜잭션의 작업 내용이 다른 트랜잭션에 어떻게 보여질지를 결정하는 기준이다. 3.2.4 Insert BufferRDBMS에서 레코드가 insert 되거나 update 될때 데이터 파일을 변경하는 작업뿐 아니라 해당 테이블에 포함된 인덱스를 업데이트 하는 작업도 필요하다. 그런 인덱스를 업데이트 하는 작업은 랜덤하게 디스크를 읽는 작업이 필요하므로 테이블에 인덱스가 많다면 이 작업은 상당히 많은 자원을 소모하게 된다. InnoDB는 변경해야 할 인덱스 페이지가 버퍼 풀에 있으면 바로 업데이트를 수행하지만, 그렇지 않고 디스크로 부터 읽어와서 업데이트해야 한다면 이를 즉시 실행하지 않고 임시 공간에 저장해 두고 바로 사용자에게 결과를 반환하는 형태로 성능을 향상시키게 되는데, 이때 사용하는 임시 메모리 공간을 인서트 버퍼(Insert Buffer) 라고 한다. 3.2.5 Redo 로그 및 로그 버퍼쿼리 문장으로 데이터를 변경하고 커밋하면 DBMS는 데이터의 ACID를 보장하기 위해 즉시 변경된 데이터의 내용을 데이터 파일로 기록해야 한다. 하지만 이런 작업은 랜덤하게 디스크에 기록해야 하므로 디스크를 바쁘게 만드는 작업이다. 그래서 대부분의 DBMS에는 변경된 데이터를 버퍼링해 두기 위해 InnoDB 버퍼 풀과 같은 장치가 포함되어 있다. 하지만 이 장치만으로는 ACID를 보장할 수 없는데 이를 위해 변경된 내용을 순차적으로 디스크에 기록하는 로그 파일을 가지고 있다. 이를 리두 로그 라고 한다. 하지만 사용량이 많은 DBMS 서버의 경우 이 리두 로그의 기록 작업이 큰 문제가 되는데, 이러한 부분을 보완하기 위한 로그 버퍼링이 존재하는데 이 로그 버퍼링에 사용되는 공간이 로그 버퍼 이다. 3.2.6 MVCC(Multi Version Concurrency Control)MVCC는 잠금을 사용하지 않는 일관된 읽기를 제공하는데 있다. InnoDB에서는 언두 로그를 이용해 이 기능을 구현한다. update 문장이 실행될 때 기존의 데이터는 언두 로그에 기록되며 새로운 데이터는 InnoDB 버퍼 풀에 기록된다. 즉 하나의 레코드에 대해 두가지 버전의 데이터가 있으며 select문을 이용해 조회를 할 경우 보여지는 데이터는 격리수준에 따라 다르다. 최종적으로 commit 이 되면 레코드의 테이터를 바꾸고, rollback 을 하면 언두 영역에 있는 데이터를 버퍼 풀로 가져온다. 즉 커밋이 된다고 언두 영역의 데이터가 바로 삭제되는게 아니다. 이 언두 영역을 필요로 하는 트랜잭션이 더는 필요 없을 때 비로소 삭제된다. 3.2.7 잠금이 없는 일관된 읽기특정 사용자가 레코드를 변경하고 아직 커밋을 수행하지 않았다 하더라도 이 변경 트랜잭션이 다른 사용자의 select 작업을 방해하지 않는다. 이를 잠금이 없는 일관된 읽기 라고 표현하며 InnoDB에서는 언두 로그를 사용하여 구현한다. 3.3 MyISAM 스토리지 엔진 아키텍처3.3.1 키 캐시InnoDB의 버퍼 풀과 비슷한 역할을 하는 것이 MyISAM의 키 캐시다. 하지만 키 캐시는 인덱스만 대상으로 작동하며 인덱스의 디스크 쓰기 작업에 대해서만 부분적으로 버퍼링 역할을 한다. 3.3.2 운영체제의 캐시 및 버퍼MyISAM 테이블의 인덱스는 키 캐시를 이용해 디스크를 검색하지 않고도 충분히 빠르게 검색할 수 있다. 하지만 MyISAM 테이블의 데이터는 디스크로부터의 I/O를 해결해 줄 만한 어떠한 캐시나 버퍼링 기능이 없다. 그래서 운영체제의 디스크 읽기/쓰기 작업으로 요청될 수 밖에 없다. 운영체제의 캐시 기능은 InnoDB 같이 데이터의 특성을 알고 전문적으로 캐시나 버퍼링을 하지는 못하지만 그래도 없는 것 보다는 낫다. 운영체제의 캐시 공간은 남는 메모리를 사용하는 것이 기본 원칙이다.","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/tags/Mysql/"}]},{"title":"3. Mysql 아키텍쳐(3.1)","slug":"Mysql-architecture","date":"2017-07-08T07:37:31.000Z","updated":"2017-07-12T05:37:35.640Z","comments":true,"path":"2017/07/08/Mysql-architecture/","link":"","permalink":"https://jumpegg.github.io/2017/07/08/Mysql-architecture/","excerpt":"","text":"3.1.1 Mysql 전체적인 구조Mysql 은 크게 Mysql엔진과 스토리지 엔진으로 구분해 볼 수 있다. Mysql 엔진Mysql 엔진은 클라이언트로 부터 접속 및 쿼리 요청을 처리하는 커넥션 핸들러 와 SQL 파서 및 전처리기, 그리고 쿼리의 최적화된 실행을 위한 옵티마이저 가 중심을 이룬다. 그리고 성능 향상을 위해 MyISAM의 키 캐시나 InnoDB의 버퍼 풀과 같은 보조 저장소 기능이 포함되 있다. 스토리지 엔진스토리지 엔진은 실질적으로 데이터를 디스크 스토리지에 저장하거나 디스크로 부터 데이터를 읽어오는 부분을 전담한다. Mysql 서버에서 Mysql엔진은 하나지만 스토리지 엔진은 여러 개를 동시에 사용할 수 있다. 핸들러 APIMysql 엔진의 쿼리 실행기에서 데이터를 읽기/쓰기 작업을 할때 스토리지에 읽기/쓰기 작업을 요청하는데, 이런 요청작업을 핸들러(Handler) 요청이라 하고, 여기에 사용되는 API를 핸들러API라고 한다. 3.1.2 Mysql 스레딩 구조Mysql은 프로세스 기반이 아니라 스레드 기반으로 작동하며 크게 포그라운드(Foreground)와 백그라운드(Background)로 구분할 수 있다. 포그라운드 스레드포그라운드 스레드는 최소한 Mysql 서버에 접속된 클라이언트의 수만큼 존재하며, 주로 클라이언트 사용자가 요청하는 쿼리 문장을 처리하는 것이 임무다. 포그라운드 스레드는 데이터를 Mysql의 데이터 버퍼나 캐시로부터 가져오며, 버퍼나 캐시에 없는 경우에는 직접 디스크의 데이터나 인덱스 파일로부터 데이터를 읽어와서 작업을 처리한다. MyISAM 테이블은 디스크 쓰기 작업까지 포그라운드 스레드가 처리하지만, InnoDB 테이블은 데이터 버퍼나 캐시까지만 포그라운드 스레드가 처리한다. 백그라운드 스레드MyISAM과는 다르게 InnoDB에서는 여러가지 작업이 백그라운드로 처리된다. 그중 가장 중요한것이 로그 스레드(Log thread) 와 버퍼의 데이터를 디스크로 내려 쓰는 작업을 처리하는 쓰기 스레드(Write thread) 이다. 3.1.3 메모리 할당 구조Mysql에서 사용되는 메모리 공간은 크게 글로벌 메모리 영역과 로컬 메모리 영역으로 구분할 수 있다.두 영역의 차이는 Mysql 서버 내에 존재하는 많은 스레드가 공유해서 사용하는 공간인지 아닌지로 구분할 수 있다. 글로벌 메모리 영역일반적으로 클라이언트 스레드의 수와 무관하게 하나의 메모리 공간만 할당된다. 로컬 메모리 영역세션 메모리 영역이라고도 표현하며, 서버상에 존재하는 클라이언트 스레드가 쿼리를 처리하는데 사용하는 메모리 영역이다. 로컬메모리는 각 클라이언트 스레드별로 독립적으로 할당되며 절대 공유되어 사용되지 않는다는 특징이 있다. 3.1.4 플러그인 스토리지 엔진 모델Mysql의 독특한 구조 중 대표적인 것이 바로 플러그인 모델이다. 쿼리 실행과정에서 데이터 읽기/쓰기 작업이 스토리지 엔진에 의해 처리된다. 복잡한 처리, 예를 들면 group by 나 order by 는 Mysql 의 쿼리 실행기에서 처리가 된다. 여기서 중요한점은 ‘하나의 쿼리 작업’ 은 ‘여러가지 하위 작업’ 으로 나뉘는데 각각의 하위 작업이 어디에서 처리되는지 구분할 줄 알아야 한다.스토리지 엔진은 대표적으로 MyISAM과 InnoDB가 있다. 123mysql&gt; show engines; -- 이 명령어를 통해 지원되는 엔진 확인가능...mysql&gt; show plugins; -- 플러그인 확인 명령어 3.1.5 쿼리 실행구조파서파서는 쿼리문장을 토큰으로 분리해 트리 형태의 구조로 만들어 내는 작업을 한다. 전처리기파서에서 만들어진 트리를 기반으로 쿼리 문장에 구조적인 문제점이 있는지 확인한다. 옵티마이저쿼리문장을 저렴한 비용으로 가장 빠르게 처리할 지 결정하는 역할을 담당한다. 실행 엔진만들어진 계획대로 각 핸들러에게 요청해서 받은 결과를 또 다른 핸들러 요청의 입력으로 연결하는 역할을 수행한다. 핸들러(스토리지 엔진)Mysql 실행 엔진의 요청에 따라 데이터를 디스크로 저장하고 디스크로부터 읽어오는 역할을 담당한다. 3.1.6 복제(Replication)데이터가 갈수록 대용량화돼 가는 것을 생각하면 확장성(Scalability)은 DBMS에서 아주 중요한 요소인데, Mysql에서 확장성을 위한 일반적인 기술로는 복제(Replication)를 들어볼 수 있다. 복제는 2대 이상의 Mysql 서버가 동일한 데이터를 담도록 실시간 동기화하는 기술이다. 서버의 역할에 따라서 master 와 slave 로 나눌 수 있다. 복제 주의사항 슬레이브는 하나의 마스터만 설정 가능 마스터와 슬레이브의 데이터 동기화를 위해 슬레이브는 일기 전용으로 설정 슬레이브 서버용 장비는 마스터와 동일한 사양이 적합 복제가 불필요한 경우에는 바이너리 로그 중지 바이너리 로그와 트랜잭션 격리 수준(Isolation level) 3.1.7 쿼리 캐시쿼리 캐시는 타 DBMS에는 없는 Mysql의 독특한 기능이다. 여러가지 복잡한 처리 절차와 꽤 큰 비용을 들여 실행된 결과를 쿼리 캐시에 담아 두고, 동일한 쿼리 요청이 왔을 때 간단하게 쿼리 캐시에서 찾아 바로 결과를 준다. 쿼리 캐시는 SQL 문장의 결과는 메모리에 캐시해 두는 기능이다. 쿼리 캐시의 구조는 간단한 키와 값의 쌍으로 관리되는 맵(Map)과 같은 데이터 구조로 구현되 있다. 여기서 키는 쿼리문장 , 값은 쿼리 실행결과 형태로 저장되어 있다. 쿼리 캐시를 사용할 경우 캐시에 있는 쿼리 결과를 넘기기 전에 다음과 같은 확인절차가 필요하다. 요청된 쿼리 문장이 쿼리 캐시에 존재하는가? 해당 사용자가 그 결과를 볼 수 있는 권한을 가지는가? 트랜젝션 내에서 실행된 쿼리인 경우, 그 결과가 가시범위 내의 트랜젝션에서 만들어진 결과인가? 쿼리에 사용된 기능이 캐시되도 동일한 결과를 보장할 수 있는가? Current_date, sysdate, rand 등과 같이 호출 시점에 따라 결과가 달라지는 요소가 있는가? 프리페어 스테이트먼트의 경우 변수가 결과에 영향을 미치지 않는가? 캐시가 만들어지고 난 이후 해당 데이터가 다른 사용자에 의해 변경되지 않았는가? 쿼리에 의해 만들어진 결과가 캐시하기에 너무 크지 않은가? 그 밖에 쿼리 캐시를 사용하지 못하게 만드는 요소가 사용됐는가? 이런 제약사항들에도 불구하고 쿼리캐시는 훌륭한 기능이다. 다음을 통해 쿼리캐시 관련 데이터들을 볼 수 있다. 123mysql&gt; show global status like 'Qcache%'; -- 쿼리캐시 관련 데이터....mysql&gt; show global status like 'Com_select'; Qcache_hits는 쿼리캐시로 처리된 select 쿼리의 수를 의미하며, Com_select 쿼리캐시에서 결과를 찾지 못해서 직접 실행한 횟수이다. 즉 Com_select 와 Qcache_hits를 더하면 Mysql 서버로 요청된 모든 select 문장의 총 합이 되는 것이다. 쿼리 캐시 히트율(%) = Qcache_hits/ (Qcache_hits + Com_select) * 100 보통 쿼리캐시 히트율이 20% 이상이면 쿼리캐시를 사용하는 것이 좋다고 한다. 하지만 히트율이 1% 라도 아주 큰 자원을 소모하는 쿼리의 경우 쿼리캐시를 사용하는 것이 좋다.","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://jumpegg.github.io/tags/Mysql/"}]},{"title":"Ionic 간단한 nav 개념잡기","slug":"ionic-nav","date":"2017-07-07T14:37:10.000Z","updated":"2017-07-12T08:59:28.349Z","comments":true,"path":"2017/07/07/ionic-nav/","link":"","permalink":"https://jumpegg.github.io/2017/07/07/ionic-nav/","excerpt":"","text":"IONIC 간단한 nav 개념잡기기본적인 페이지 이동ionic 은 router 의 개념이 stack을 통해 view 를 push/pop 하는 형식이다.(이것은 한글인가 영어인가….) 1234567891011import &#123;NavController&#125; from 'ionic-angular';.....@Component(&#123; templateUrl: 'yourIndex.html';&#125;)export class IndexPage&#123; constructor( public navCtrl:NavController)&#123; &#125;&#125; 여기서 클래스 이름 그대로 NavController 가 네비게이션 컨트롤러 역할을 한다. 페이지를 넘기고 싶다면 push 를 이용해서 이동하고 싶은 페이지의 컴포넌트를 입력시키면 된다. 1234567891011121314151617import &#123;NavController&#125; from 'ionic-angular';.....import &#123;SecondPage&#125; from '../Component/SecondPage/SecondPage';@Component(&#123; templateUrl: 'yourIndex.html';&#125;)export class IndexPage&#123; constructor( public navCtrl:NavController)&#123; &#125; moveToSecond()&#123; this.navCtrl.push(SecondPage); //push 를 이용한 페이지 이동 &#125;&#125; 페이지간 데이터 전송페이지간 데이터를 전송하고 싶다면 push에 파라메터로 넘기고싶은 데이터의 Object를 파라메터로 넘겨주고, 받는 페이지에서는 navParams.get() 을 이용해서 받으면 된다. 파라메터를 넘기는 IndexPage 1234567891011121314151617import &#123;NavController&#125; from 'ionic-angular';.....import &#123;SecondPage&#125; from '../Component/SecondPage/SecondPage';@Component(&#123; templateUrl: 'yourIndex.html';&#125;)export class IndexPage&#123; constructor( public navCtrl:NavController)&#123; &#125; moveToSecond()&#123; this.navCtrl.push(SecondPage,&#123;msg: \"It's work!!\"&#125;); // 컴포넌트에 msg 라는 파라메터 넘김 &#125;&#125; 파라메터를 받는 SecondPage 12345678910111213141516import &#123;NavController, NavParams&#125; from 'ionic-angular';....@Component(&#123; templateUrl: 'yourSecond.html';&#125;)export class SecondPage&#123; constructor( public navCtrl:NavController, public navParams:NavParams)&#123; &#125; ionViewDidLoad() &#123; console.log(this.navParams.get('msg')); // 파라메터에 접근 &#125;&#125; rootPage 설정페이지가 이동을 하면 새로 root 페이지를 설정해줘야 할 때가 있다. 예를들면 로그인 이후 화면? 같은것을 예로 들 수 있다. setRoot()를 이용하면 root 페이지를 바꿀 수 있다. 1234567891011121314151617import &#123;NavController, NavParams&#125; from 'ionic-angular';....@Component(&#123; templateUrl: 'yourSecond.html';&#125;)export class SecondPage&#123; constructor( public navCtrl:NavController, public navParams:NavParams)&#123; &#125; ionViewDidLoad() &#123; console.log(this.navParams.get('msg')); // 파라메터에 접근 this.navCtrl.setRoot(SecondPage); // SecondPage로 root를 바꾼다 &#125;&#125; setRoot() 사용시 주의점은 root를 바꿔주면서 해당 페이지로 이동시키기 때문에 setRoot() 를 사용하는 지점을 잘 생각해야 한다. 실수로 자기 자신을 루트로 잡아봤는데 무한루프가 도는 것을 볼 수 있었다. 참조 사이트http://www.joshmorony.com/a-simple-guide-to-navigation-in-ionic-2/고 투 더 멘토","categories":[{"name":"ionic2","slug":"ionic2","permalink":"https://jumpegg.github.io/categories/ionic2/"}],"tags":[{"name":"ionic2-nav","slug":"ionic2-nav","permalink":"https://jumpegg.github.io/tags/ionic2-nav/"}]},{"title":"Hexo 를 시작해보자","slug":"start","date":"2017-07-06T09:15:19.000Z","updated":"2017-07-06T09:31:29.888Z","comments":true,"path":"2017/07/06/start/","link":"","permalink":"https://jumpegg.github.io/2017/07/06/start/","excerpt":"","text":"hexo 가 있는건 진작 알고 있었는데, 혼자 하는 프로젝트가 어느정도 끝나가면서 사용했던 개념들을 기록 할 공간이 필요했다. 그래서 이번에 기록 할 겸 hexo도 사용해볼겸 해서 블로그를 시작하게 되었다. 우선 hexo 를 시작해보자 Hexo 를 시작해보자hexo 설치1$ npm install -g hexo-cli cli 환경이 익숙치 않은 사람들에게는 낯설겠지만 hexo 는 cli 환경에서 페이지를 생성하고 markdown 문법을 사용해서 내용을 구성한다. 아무튼, 명령어를 치면 이제 hexo 명령어 들을 사용할 수 있다. hexo init1$ hexo init [폴더명] init 명령어를 사용하면 해당 폴더에 hexo를 사용하기 위한 기본 구조와 파일들이 생성된다 이제 생성한 폴더에 들어가서 hexo 명령어들을 이용해서 작업하면 된다. hexo new1$ hexo new [포스트명] 폴더 안으로 들어가서 new 명령어를 실행하면 [포스트명] 으로 source/_posts/ 폴더안에 파일이 생성된다. 이 파일들이 우리가 만드는 컨텐츠가 된다.","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://jumpegg.github.io/categories/Hexo/"}],"tags":[]}]}